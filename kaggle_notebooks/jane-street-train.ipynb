{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":84493,"databundleVersionId":9871156,"sourceType":"competition"},{"sourceId":10140532,"sourceType":"datasetVersion","datasetId":5993004},{"sourceId":10277443,"sourceType":"datasetVersion","datasetId":6123233}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport glob\nimport polars as pl\nimport lightgbm as lgb\nfrom sklearn.model_selection import KFold, train_test_split\nfrom sklearn.metrics import mean_absolute_error,r2_score\nimport tqdm\nimport pickle\nfrom sklearnex import patch_sklearn\nimport logging\n\npatch_sklearn()\nlogging.getLogger('sklearnex').setLevel(logging.WARNING)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-12-26T17:56:46.306712Z","iopub.execute_input":"2024-12-26T17:56:46.307129Z","iopub.status.idle":"2024-12-26T17:56:50.121476Z","shell.execute_reply.started":"2024-12-26T17:56:46.307091Z","shell.execute_reply":"2024-12-26T17:56:50.120118Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## Get summary of missing values across the data files","metadata":{}},{"cell_type":"code","source":"seed = 123\nnp.random.seed(123)\ncols= ['feature_06', 'feature_22', 'feature_24', 'feature_38', 'feature_14', 'feature_28', 'feature_05', 'feature_67', 'feature_30', 'feature_60', 'feature_20', \n       'feature_61', 'feature_23', 'feature_70', 'feature_25', 'feature_29', 'feature_36', 'feature_09', 'feature_10', 'feature_11', 'feature_69', 'feature_07', \n       'feature_72', 'feature_71']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T17:56:50.123956Z","iopub.execute_input":"2024-12-26T17:56:50.124671Z","iopub.status.idle":"2024-12-26T17:56:50.131178Z","shell.execute_reply.started":"2024-12-26T17:56:50.124617Z","shell.execute_reply":"2024-12-26T17:56:50.130017Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"path_name = \"/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=*/part-0.parquet\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T17:56:50.132555Z","iopub.execute_input":"2024-12-26T17:56:50.132926Z","iopub.status.idle":"2024-12-26T17:56:50.145202Z","shell.execute_reply.started":"2024-12-26T17:56:50.132867Z","shell.execute_reply":"2024-12-26T17:56:50.143581Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def get_missing_summary(path_name):\n    data = {}\n    total_length = 0\n    for path in glob.glob(path_name):\n        parquet_file = pl.scan_parquet(path).collect()\n        parquet_dict = parquet_file.null_count().to_dicts()[0]\n        for feat, missing in parquet_dict.items():\n            data[feat] = data.get(feat, 0) + missing\n        total_length += len(parquet_file)\n    for feat, value in data.items():\n        data[feat] = data[feat]/total_length * 100\n\n    return pd.Series(data, name=\"Missing Data Summary\").sort_values(ascending=False).to_frame()\n\ndef get_total_symbols(path_name):\n    symbols = []\n    for path in glob.glob(path_name):\n        parquet_file = pd.read_parquet(path)\n        symbols = list(set(symbols + parquet_file['symbol_id'].unique().tolist()))\n    return symbols\n\ndef get_numpy_from_parquet(path, cols, instrument=2):\n    parquet_file = pl.scan_parquet(path)\n    instrument_data = parquet_file.filter(pl.col(\"symbol_id\") == instrument).collect().sort([\"date_id\", \"time_id\"])\n    return instrument_data.select(cols+['responder_6']).to_numpy()\n\ndef get_financial_instrument(path_name, emb_dim, cols, instrument):\n    data = np.empty((0, emb_dim+1), dtype=np.float32)  # Start with an empty array with the correct number of columns\n    for path in glob.glob(path_name):\n        array_to_concat = get_numpy_from_parquet(path=path, cols=cols, instrument=instrument)\n        data = np.vstack((data, array_to_concat))\n    return data\n\ndef get_missing_summary_by_symbol(path_name):\n    series = []\n    for symbol in tqdm.tqdm(symbols, desc=\"Processing financial instruments\"):\n        parquet_file = get_financial_parquet(path_name, instrument=symbol)\n        parquet_file = parquet_file.null_count()/len(parquet_file)*100\n        series.append(pd.Series(parquet_file.to_dicts()[0], name=f\"Symbol {symbol}\").to_frame())\n\n    return pd.concat(series, axis=1, join=\"inner\")\n\ndef get_financial_parquet(path_name, instrument=2):\n    data = []\n    for path in glob.glob(path_name):\n        parquet_file = pl.scan_parquet(path)\n        instrument_data = parquet_file.filter(pl.col(\"symbol_id\") == instrument).collect().sort([\"date_id\", \"time_id\"])\n        data.append(instrument_data)\n    return pl.concat(data, how=\"vertical\")\n\ndef get_mean(path_name, cols):\n    hash_map = {}\n    for symbol in tqdm.tqdm(symbols, desc=\"Processing financial instruments\"):\n        parquet_file = get_financial_parquet(path_name, instrument=symbol)\n        hash_map[symbol] = parquet_file.select(cols).mean().to_dicts()[0]\n        \n    return hash_map\n\ndef rolling_window(data, window):\n    size = data.shape[0] - window + 1\n    emb = data.shape[1]-1\n    inputs = np.lib.stride_tricks.sliding_window_view(data[:, :-1], \n                                                      (window, emb), \n                                                      axis=(0, 1)).reshape(size, window*emb)\n    targets = data[window-1:, -1]\n    \n    return inputs, targets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T17:56:50.146823Z","iopub.execute_input":"2024-12-26T17:56:50.147290Z","iopub.status.idle":"2024-12-26T17:56:50.167227Z","shell.execute_reply.started":"2024-12-26T17:56:50.147243Z","shell.execute_reply":"2024-12-26T17:56:50.164851Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"symbols = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T17:56:50.170576Z","iopub.execute_input":"2024-12-26T17:56:50.171091Z","iopub.status.idle":"2024-12-26T17:56:50.180915Z","shell.execute_reply.started":"2024-12-26T17:56:50.171041Z","shell.execute_reply":"2024-12-26T17:56:50.179515Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"missing_summary = get_missing_summary(path_name)\n# symbols = get_total_symbols(path_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T17:56:50.182291Z","iopub.execute_input":"2024-12-26T17:56:50.182862Z","iopub.status.idle":"2024-12-26T17:57:47.173630Z","shell.execute_reply.started":"2024-12-26T17:56:50.182796Z","shell.execute_reply":"2024-12-26T17:57:47.171738Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"print(f\"There are a total of {len(symbols)} financial instruments across the data\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T17:57:47.176177Z","iopub.execute_input":"2024-12-26T17:57:47.176907Z","iopub.status.idle":"2024-12-26T17:57:47.186104Z","shell.execute_reply.started":"2024-12-26T17:57:47.176824Z","shell.execute_reply":"2024-12-26T17:57:47.184752Z"}},"outputs":[{"name":"stdout","text":"There are a total of 39 financial instruments across the data\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"## Features with no missing values","metadata":{}},{"cell_type":"code","source":"print(sorted(missing_summary.tail(45).index.tolist()))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T17:57:47.187379Z","iopub.execute_input":"2024-12-26T17:57:47.187768Z","iopub.status.idle":"2024-12-26T17:57:47.201577Z","shell.execute_reply.started":"2024-12-26T17:57:47.187691Z","shell.execute_reply":"2024-12-26T17:57:47.200412Z"}},"outputs":[{"name":"stdout","text":"['date_id', 'feature_05', 'feature_06', 'feature_07', 'feature_09', 'feature_10', 'feature_11', 'feature_12', 'feature_13', 'feature_14', 'feature_20', 'feature_22', 'feature_23', 'feature_24', 'feature_25', 'feature_28', 'feature_29', 'feature_30', 'feature_34', 'feature_35', 'feature_36', 'feature_38', 'feature_48', 'feature_49', 'feature_59', 'feature_60', 'feature_61', 'feature_67', 'feature_68', 'feature_69', 'feature_70', 'feature_71', 'feature_72', 'responder_0', 'responder_1', 'responder_2', 'responder_3', 'responder_4', 'responder_5', 'responder_6', 'responder_7', 'responder_8', 'symbol_id', 'time_id', 'weight']\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"len(missing_summary.index) #Total Features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T17:57:47.203058Z","iopub.execute_input":"2024-12-26T17:57:47.203435Z","iopub.status.idle":"2024-12-26T17:57:47.222636Z","shell.execute_reply.started":"2024-12-26T17:57:47.203398Z","shell.execute_reply":"2024-12-26T17:57:47.221442Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"92"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"clean_cols = sorted(missing_summary.tail(45).index.tolist())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T17:57:47.224085Z","iopub.execute_input":"2024-12-26T17:57:47.224384Z","iopub.status.idle":"2024-12-26T17:57:47.235107Z","shell.execute_reply.started":"2024-12-26T17:57:47.224355Z","shell.execute_reply":"2024-12-26T17:57:47.233981Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"print(clean_cols)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T17:58:25.745770Z","iopub.execute_input":"2024-12-26T17:58:25.746236Z","iopub.status.idle":"2024-12-26T17:58:25.753200Z","shell.execute_reply.started":"2024-12-26T17:58:25.746199Z","shell.execute_reply":"2024-12-26T17:58:25.751566Z"}},"outputs":[{"name":"stdout","text":"['date_id', 'feature_05', 'feature_06', 'feature_07', 'feature_09', 'feature_10', 'feature_11', 'feature_12', 'feature_13', 'feature_14', 'feature_20', 'feature_22', 'feature_23', 'feature_24', 'feature_25', 'feature_28', 'feature_29', 'feature_30', 'feature_34', 'feature_35', 'feature_36', 'feature_38', 'feature_48', 'feature_49', 'feature_59', 'feature_60', 'feature_61', 'feature_67', 'feature_68', 'feature_69', 'feature_70', 'feature_71', 'feature_72', 'responder_0', 'responder_1', 'responder_2', 'responder_3', 'responder_4', 'responder_5', 'responder_6', 'responder_7', 'responder_8', 'symbol_id', 'time_id', 'weight']\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"missing_summary","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T20:26:46.072181Z","iopub.execute_input":"2024-12-20T20:26:46.072678Z","iopub.status.idle":"2024-12-20T20:26:46.104761Z","shell.execute_reply.started":"2024-12-20T20:26:46.072627Z","shell.execute_reply":"2024-12-20T20:26:46.103385Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"             Missing Data Summary\nfeature_27              17.900406\nfeature_21              17.900406\nfeature_31              17.900406\nfeature_26              17.900406\nfeature_39               9.125593\n...                           ...\nfeature_36               0.000000\nfeature_38               0.000000\ntime_id                  0.000000\nfeature_48               0.000000\nresponder_8              0.000000\n\n[92 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Missing Data Summary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>feature_27</th>\n      <td>17.900406</td>\n    </tr>\n    <tr>\n      <th>feature_21</th>\n      <td>17.900406</td>\n    </tr>\n    <tr>\n      <th>feature_31</th>\n      <td>17.900406</td>\n    </tr>\n    <tr>\n      <th>feature_26</th>\n      <td>17.900406</td>\n    </tr>\n    <tr>\n      <th>feature_39</th>\n      <td>9.125593</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>feature_36</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>feature_38</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>time_id</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>feature_48</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>responder_8</th>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>92 rows × 1 columns</p>\n</div>"},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"#### Columns with missing values < 1%","metadata":{}},{"cell_type":"code","source":"fill_cols = sorted(missing_summary.loc[(missing_summary[\"Missing Data Summary\"] < 20) & (missing_summary[\"Missing Data Summary\"] >= 1)].index.tolist())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T20:26:46.106616Z","iopub.execute_input":"2024-12-20T20:26:46.107026Z","iopub.status.idle":"2024-12-20T20:26:46.118144Z","shell.execute_reply.started":"2024-12-20T20:26:46.106980Z","shell.execute_reply":"2024-12-20T20:26:46.116960Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"print(fill_cols)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T20:26:46.119514Z","iopub.execute_input":"2024-12-20T20:26:46.119920Z","iopub.status.idle":"2024-12-20T20:26:46.131409Z","shell.execute_reply.started":"2024-12-20T20:26:46.119869Z","shell.execute_reply":"2024-12-20T20:26:46.130070Z"}},"outputs":[{"name":"stdout","text":"['feature_00', 'feature_01', 'feature_02', 'feature_03', 'feature_04', 'feature_15', 'feature_21', 'feature_26', 'feature_27', 'feature_31', 'feature_32', 'feature_33', 'feature_39', 'feature_41', 'feature_42', 'feature_44', 'feature_50', 'feature_52', 'feature_53', 'feature_55', 'feature_58', 'feature_73', 'feature_74']\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# symbol_summary = get_missing_summary_by_symbol(path_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T20:26:46.132923Z","iopub.execute_input":"2024-12-20T20:26:46.133537Z","iopub.status.idle":"2024-12-20T20:26:46.146118Z","shell.execute_reply.started":"2024-12-20T20:26:46.133436Z","shell.execute_reply":"2024-12-20T20:26:46.144662Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"## Assess the missing values summary for each of the financial instrument","metadata":{}},{"cell_type":"code","source":"all_feats = sorted(missing_summary.index.tolist())[1:-12]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T20:26:46.147487Z","iopub.execute_input":"2024-12-20T20:26:46.147847Z","iopub.status.idle":"2024-12-20T20:26:46.160733Z","shell.execute_reply.started":"2024-12-20T20:26:46.147801Z","shell.execute_reply":"2024-12-20T20:26:46.159423Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# %time nan_means = get_mean(path_name, all_feats)\n# with open('/kaggle/working/nan_means.p', 'wb') as fp:\n#     pickle.dump(nan_means, fp, protocol=pickle.HIGHEST_PROTOCOL)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T20:26:46.162572Z","iopub.execute_input":"2024-12-20T20:26:46.163116Z","iopub.status.idle":"2024-12-20T20:26:46.174273Z","shell.execute_reply.started":"2024-12-20T20:26:46.163062Z","shell.execute_reply":"2024-12-20T20:26:46.173195Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# with open('/kaggle/working/agg_means.p', 'wb') as fp:\n#     pickle.dump(pd.DataFrame(nan_means).mean(axis=1).to_dict(), fp, protocol=pickle.HIGHEST_PROTOCOL)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T20:26:46.175827Z","iopub.execute_input":"2024-12-20T20:26:46.176525Z","iopub.status.idle":"2024-12-20T20:26:46.190386Z","shell.execute_reply.started":"2024-12-20T20:26:46.176473Z","shell.execute_reply":"2024-12-20T20:26:46.188858Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"# Select best features","metadata":{}},{"cell_type":"code","source":"with open('/kaggle/input/fillnans/nan_means.p', 'rb') as fp:\n    nan_means = pickle.load(fp)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T20:26:46.192257Z","iopub.execute_input":"2024-12-20T20:26:46.192672Z","iopub.status.idle":"2024-12-20T20:26:46.219952Z","shell.execute_reply.started":"2024-12-20T20:26:46.192611Z","shell.execute_reply":"2024-12-20T20:26:46.218321Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"import json\nwith open(\"/kaggle/input/feature-importance/features_information_v2.json\", mode=\"r\") as file:\n    feature_importance = json.load(file)\n\ntop_k_comb = sorted(feature_importance.items(), key=lambda x: (x[-1], x[0]), reverse=False)[:10] #best feature combination\ncols = top_k_comb[0][0].split(\"/\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T20:26:46.221471Z","iopub.execute_input":"2024-12-20T20:26:46.221864Z","iopub.status.idle":"2024-12-20T20:26:46.234105Z","shell.execute_reply.started":"2024-12-20T20:26:46.221825Z","shell.execute_reply":"2024-12-20T20:26:46.232703Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"def numpy_fillna(arr, fillna_dict, cols):\n    arr_copy = arr.copy()  # Avoid modifying the original array\n    for idx, col in enumerate(cols):\n        arr_copy[:, idx] = np.nan_to_num(arr_copy[:, idx], nan=fillna_dict[col])\n    return arr_copy\n\ndef rolling_window(data, window):\n    size = data.shape[0] - window + 1\n    emb = data.shape[1]\n    inputs = np.lib.stride_tricks.sliding_window_view(data, \n                                                      (window, emb), \n                                                      axis=(0, 1)).reshape(size, window*emb)\n    \n    return inputs\n\ndef evaluate_model(symbol, path_name, params, cols, fillna, window=4, \n                   n_splits=5, seed=seed, shuffle=True):\n    \n    kfold = KFold(n_splits=n_splits, random_state=seed, shuffle=shuffle)\n    scores = []\n    data = get_financial_instrument(path_name, emb_dim=len(cols), cols=cols, instrument=symbol)\n    windowed_data = numpy_fillna(data[:, :-1], fillna, cols=cols)\n    windowed_data = rolling_window(windowed_data, window)\n    targets = data[window-1:, -1]\n        \n    r2_train = []\n    r2_test = []\n    #Define cross validation\n    for train_ind, test_ind in kfold.split(windowed_data):\n        #Split train data for cross validation\n        X_train, y_train, X_test, y_test = windowed_data[train_ind], targets[train_ind], windowed_data[test_ind], targets[test_ind]\n        model = lgb.LGBMRegressor(**params)\n        model.fit(X_train, y_train, eval_set=[(X_test, y_test)])\n\n        #Generate predictions \n        y_preds = model.predict(X_test)\n        preds = model.predict(X_train)\n        r2_train.append(r2_score(y_train, preds)) #append r2_score\n        r2_test.append(r2_score(y_test, y_preds))\n        scores.append(mean_absolute_error(y_test, y_preds)) # append model error\n    \n    score = np.mean(scores)\n    print(f\"\"\"Financial Instrument: {symbol}\\nFeature Combination: {cols}\\nMean absolute error: {score:.3f}\\nR2 Score Train: {np.mean(r2_train):.2f}\\nR2 Score Test: {np.mean(r2_test):.2f}\"\"\")\n    print()\n    \n    return score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T20:26:46.235615Z","iopub.execute_input":"2024-12-20T20:26:46.236036Z","iopub.status.idle":"2024-12-20T20:26:46.250138Z","shell.execute_reply.started":"2024-12-20T20:26:46.235988Z","shell.execute_reply":"2024-12-20T20:26:46.248972Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"params = {\"boosting_type\": 'gbdt',\"num_leaves\": 77, \"max_depth\": 7, \"colsample_bytree\": 0.45, \"learning_rate\": 0.45,\n          'min_child_samples': 20,'min_split_gain': 0.45, \"n_estimators\": 200,\"verbose\": -1, \"metric\": \"mae\",\n          \"force_col_wise\": True # \"device\": \"gpu\"  # Enable GPU, if available\n         }\nbest_scores = {'feature_06/feature_22/feature_24/feature_37/feature_47/feature_70/feature_30/feature_05/feature_20/feature_14/feature_28/feature_29/feature_08/feature_25/feature_23/feature_67/feature_38/feature_61/feature_78/feature_62/feature_19/feature_36/feature_69/feature_72/feature_65/feature_09/feature_10/feature_11/feature_07/feature_60/feature_56/feature_01/feature_58/feature_31/feature_26/feature_27/feature_04/feature_74/feature_50': 0.4256425408209205, 'feature_06/feature_22/feature_24/feature_37/feature_47/feature_70/feature_30/feature_05/feature_20/feature_14/feature_28/feature_29/feature_08/feature_25/feature_23/feature_67/feature_38/feature_61/feature_78/feature_62/feature_19/feature_36/feature_69/feature_72/feature_65/feature_09/feature_10/feature_11/feature_07/feature_60/feature_56/feature_01/feature_58/feature_31/feature_26/feature_27/feature_04/feature_74/feature_50/feature_33': 0.4256577751378833, 'feature_06/feature_22/feature_24/feature_37/feature_47/feature_70/feature_30/feature_05/feature_20/feature_14/feature_28/feature_29/feature_08/feature_25/feature_23/feature_67/feature_38/feature_61/feature_78/feature_62/feature_19/feature_36/feature_69/feature_72/feature_65/feature_09/feature_10/feature_11/feature_07/feature_60/feature_56/feature_01/feature_58/feature_31/feature_26/feature_27/feature_04/feature_74/feature_50/feature_33/feature_39': 0.4257329168282258, 'feature_06/feature_22/feature_24/feature_37/feature_47/feature_70/feature_30/feature_05/feature_20/feature_14/feature_28/feature_29/feature_08/feature_25/feature_23/feature_67/feature_38/feature_61/feature_78/feature_62/feature_19/feature_36/feature_69/feature_72/feature_65/feature_09/feature_10/feature_11/feature_07/feature_60/feature_56/feature_01/feature_58/feature_31/feature_26/feature_27/feature_04/feature_74/feature_50/feature_33/feature_39/feature_21': 0.4256889860553527, 'feature_06/feature_22/feature_24/feature_37/feature_47/feature_70/feature_30/feature_05/feature_20/feature_14/feature_28/feature_29/feature_08/feature_25/feature_23/feature_67/feature_38/feature_61/feature_78/feature_62/feature_19/feature_36/feature_69/feature_72/feature_65/feature_09/feature_10/feature_11/feature_07/feature_60/feature_56/feature_01/feature_58/feature_31/feature_26/feature_27/feature_04/feature_74/feature_50/feature_33/feature_39/feature_21/feature_73': 0.42578237985077905, 'feature_06/feature_22/feature_24/feature_37/feature_47/feature_70/feature_30/feature_05/feature_20/feature_14/feature_28/feature_29/feature_08/feature_25/feature_23/feature_67/feature_38/feature_61/feature_78/feature_62/feature_19/feature_36/feature_69/feature_72/feature_65/feature_09/feature_10/feature_11/feature_07/feature_60/feature_56/feature_01/feature_58/feature_31/feature_26/feature_27/feature_04/feature_74/feature_50/feature_33/feature_39/feature_21/feature_73/feature_53': 0.42552762277622824, 'feature_06/feature_22/feature_24/feature_37/feature_47/feature_70/feature_30/feature_05/feature_20/feature_14/feature_28/feature_29/feature_08/feature_25/feature_23/feature_67/feature_38/feature_61/feature_78/feature_62/feature_19/feature_36/feature_69/feature_72/feature_65/feature_09/feature_10/feature_11/feature_07/feature_60/feature_56/feature_01/feature_58/feature_31/feature_26/feature_27/feature_04/feature_74/feature_50/feature_33/feature_39/feature_21/feature_73/feature_53/feature_15': 0.4256377532475385, 'feature_06/feature_22/feature_24/feature_37/feature_47/feature_70/feature_30/feature_05/feature_20/feature_14/feature_28/feature_29/feature_08/feature_25/feature_23/feature_67/feature_38/feature_61/feature_78/feature_62/feature_19/feature_36/feature_69/feature_72/feature_65/feature_09/feature_10/feature_11/feature_07/feature_60/feature_56/feature_01/feature_58/feature_31/feature_26/feature_27/feature_04/feature_74/feature_50/feature_33/feature_39/feature_21/feature_73/feature_53/feature_15/feature_32': 0.42526072871252313, 'feature_06/feature_22/feature_24/feature_37/feature_47/feature_70/feature_30/feature_05/feature_20/feature_14/feature_28/feature_29/feature_08/feature_25/feature_23/feature_67/feature_38/feature_61/feature_78/feature_62/feature_19/feature_36/feature_69/feature_72/feature_65/feature_09/feature_10/feature_11/feature_07/feature_60/feature_56/feature_01/feature_58/feature_31/feature_26/feature_27/feature_04/feature_74/feature_50/feature_33/feature_39/feature_21/feature_73/feature_53/feature_15/feature_32/feature_41': 0.4259224310317046, 'feature_06/feature_22/feature_24/feature_37/feature_47/feature_70/feature_30/feature_05/feature_20/feature_14/feature_28/feature_29/feature_08/feature_25/feature_23/feature_67/feature_38/feature_61/feature_78/feature_62/feature_19/feature_36/feature_69/feature_72/feature_65/feature_09/feature_10/feature_11/feature_07/feature_60/feature_56/feature_01/feature_58/feature_31/feature_26/feature_27/feature_04/feature_74/feature_50/feature_33/feature_39/feature_21/feature_73/feature_53/feature_15/feature_32/feature_41/feature_55': 0.42625380089287435, 'feature_06/feature_22/feature_24/feature_37/feature_47/feature_70/feature_30/feature_05/feature_20/feature_14/feature_28/feature_29/feature_08/feature_25/feature_23/feature_67/feature_38/feature_61/feature_78/feature_62/feature_19/feature_36/feature_69/feature_72/feature_65/feature_09/feature_10/feature_11/feature_07/feature_60/feature_56/feature_01/feature_58/feature_31/feature_26/feature_27/feature_04/feature_74/feature_50/feature_33/feature_39/feature_21/feature_73/feature_53/feature_15/feature_32/feature_41/feature_55/feature_02': 0.426230088333463, 'feature_06/feature_22/feature_24/feature_37/feature_47/feature_70/feature_30/feature_05/feature_20/feature_14/feature_28/feature_29/feature_08/feature_25/feature_23/feature_67/feature_38/feature_61/feature_78/feature_62/feature_19/feature_36/feature_69/feature_72/feature_65/feature_09/feature_10/feature_11/feature_07/feature_60/feature_56/feature_01/feature_58/feature_31/feature_26/feature_27/feature_04/feature_74/feature_50/feature_33/feature_39/feature_21/feature_73/feature_53/feature_15/feature_32/feature_41/feature_55/feature_02/feature_42': 0.42629852915466265}\nbest_features = ['feature_06', 'feature_22', 'feature_24', 'feature_37', 'feature_47', 'feature_70', 'feature_30', 'feature_05', 'feature_20', 'feature_14', 'feature_28', 'feature_29', 'feature_08', 'feature_25', 'feature_23', 'feature_67', 'feature_38', 'feature_61', 'feature_78', 'feature_62', 'feature_19', 'feature_36', 'feature_69', 'feature_72', 'feature_65', 'feature_09', 'feature_10', 'feature_11', 'feature_07', 'feature_60', 'feature_56', 'feature_01', 'feature_58', 'feature_31', 'feature_26', 'feature_27', 'feature_04', 'feature_74', 'feature_50', 'feature_33', 'feature_39', 'feature_21', 'feature_73', 'feature_53', 'feature_15', 'feature_32', 'feature_41', 'feature_55', 'feature_02', 'feature_42']\nsymbol = 1\nfeature_cols = sorted(cols+fill_cols)\n\nfor _ in tqdm.tqdm(range(len(best_features),len(feature_cols)), desc=\"Evaluating feature combinations\"):\n    feature_score = {}\n    for col in feature_cols:\n        if col not in best_features:  # Check if the column is not already evaluated\n            current_features = best_features + [col]  # Create the current feature list\n            feature_score[\"/\".join(current_features)] = evaluate_model(\n                symbol, path_name, params, cols=current_features, fillna=nan_means[symbol],\n                window=4, n_splits=5, seed=seed, shuffle=True\n            )\n    \n    # Select the best feature combination from the current iteration\n    k, v = sorted(feature_score.items(), key=lambda v: v[-1], reverse=False)[0]\n    best_scores[k] = v\n\n    # Add the new best features to the set\n    best_features.append(k.split(\"/\")[-1])","metadata":{"execution":{"iopub.status.busy":"2024-12-18T10:24:24.400725Z","iopub.execute_input":"2024-12-18T10:24:24.401060Z","iopub.status.idle":"2024-12-18T12:03:04.519964Z","shell.execute_reply.started":"2024-12-18T10:24:24.401024Z","shell.execute_reply":"2024-12-18T12:03:04.503875Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Evaluating feature combinations:   0%|          | 0/4 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Financial Instrument: 1\nFeature Combination: ['feature_06', 'feature_22', 'feature_24', 'feature_37', 'feature_47', 'feature_70', 'feature_30', 'feature_05', 'feature_20', 'feature_14', 'feature_28', 'feature_29', 'feature_08', 'feature_25', 'feature_23', 'feature_67', 'feature_38', 'feature_61', 'feature_78', 'feature_62', 'feature_19', 'feature_36', 'feature_69', 'feature_72', 'feature_65', 'feature_09', 'feature_10', 'feature_11', 'feature_07', 'feature_60', 'feature_56', 'feature_01', 'feature_58', 'feature_31', 'feature_26', 'feature_27', 'feature_04', 'feature_74', 'feature_50', 'feature_33', 'feature_39', 'feature_21', 'feature_73', 'feature_53', 'feature_15', 'feature_32', 'feature_41', 'feature_55', 'feature_02', 'feature_42', 'feature_00']\nMean absolute error: 0.427\nR2 Score Train: 0.37\nR2 Score Test: 0.25\n\nFinancial Instrument: 1\nFeature Combination: ['feature_06', 'feature_22', 'feature_24', 'feature_37', 'feature_47', 'feature_70', 'feature_30', 'feature_05', 'feature_20', 'feature_14', 'feature_28', 'feature_29', 'feature_08', 'feature_25', 'feature_23', 'feature_67', 'feature_38', 'feature_61', 'feature_78', 'feature_62', 'feature_19', 'feature_36', 'feature_69', 'feature_72', 'feature_65', 'feature_09', 'feature_10', 'feature_11', 'feature_07', 'feature_60', 'feature_56', 'feature_01', 'feature_58', 'feature_31', 'feature_26', 'feature_27', 'feature_04', 'feature_74', 'feature_50', 'feature_33', 'feature_39', 'feature_21', 'feature_73', 'feature_53', 'feature_15', 'feature_32', 'feature_41', 'feature_55', 'feature_02', 'feature_42', 'feature_03']\nMean absolute error: 0.427\nR2 Score Train: 0.37\nR2 Score Test: 0.25\n\nFinancial Instrument: 1\nFeature Combination: ['feature_06', 'feature_22', 'feature_24', 'feature_37', 'feature_47', 'feature_70', 'feature_30', 'feature_05', 'feature_20', 'feature_14', 'feature_28', 'feature_29', 'feature_08', 'feature_25', 'feature_23', 'feature_67', 'feature_38', 'feature_61', 'feature_78', 'feature_62', 'feature_19', 'feature_36', 'feature_69', 'feature_72', 'feature_65', 'feature_09', 'feature_10', 'feature_11', 'feature_07', 'feature_60', 'feature_56', 'feature_01', 'feature_58', 'feature_31', 'feature_26', 'feature_27', 'feature_04', 'feature_74', 'feature_50', 'feature_33', 'feature_39', 'feature_21', 'feature_73', 'feature_53', 'feature_15', 'feature_32', 'feature_41', 'feature_55', 'feature_02', 'feature_42', 'feature_44']\nMean absolute error: 0.427\nR2 Score Train: 0.37\nR2 Score Test: 0.25\n\n","output_type":"stream"},{"name":"stderr","text":"Evaluating feature combinations:  25%|██▌       | 1/4 [39:02<1:57:08, 2342.93s/it]","output_type":"stream"},{"name":"stdout","text":"Financial Instrument: 1\nFeature Combination: ['feature_06', 'feature_22', 'feature_24', 'feature_37', 'feature_47', 'feature_70', 'feature_30', 'feature_05', 'feature_20', 'feature_14', 'feature_28', 'feature_29', 'feature_08', 'feature_25', 'feature_23', 'feature_67', 'feature_38', 'feature_61', 'feature_78', 'feature_62', 'feature_19', 'feature_36', 'feature_69', 'feature_72', 'feature_65', 'feature_09', 'feature_10', 'feature_11', 'feature_07', 'feature_60', 'feature_56', 'feature_01', 'feature_58', 'feature_31', 'feature_26', 'feature_27', 'feature_04', 'feature_74', 'feature_50', 'feature_33', 'feature_39', 'feature_21', 'feature_73', 'feature_53', 'feature_15', 'feature_32', 'feature_41', 'feature_55', 'feature_02', 'feature_42', 'feature_52']\nMean absolute error: 0.427\nR2 Score Train: 0.37\nR2 Score Test: 0.25\n\nFinancial Instrument: 1\nFeature Combination: ['feature_06', 'feature_22', 'feature_24', 'feature_37', 'feature_47', 'feature_70', 'feature_30', 'feature_05', 'feature_20', 'feature_14', 'feature_28', 'feature_29', 'feature_08', 'feature_25', 'feature_23', 'feature_67', 'feature_38', 'feature_61', 'feature_78', 'feature_62', 'feature_19', 'feature_36', 'feature_69', 'feature_72', 'feature_65', 'feature_09', 'feature_10', 'feature_11', 'feature_07', 'feature_60', 'feature_56', 'feature_01', 'feature_58', 'feature_31', 'feature_26', 'feature_27', 'feature_04', 'feature_74', 'feature_50', 'feature_33', 'feature_39', 'feature_21', 'feature_73', 'feature_53', 'feature_15', 'feature_32', 'feature_41', 'feature_55', 'feature_02', 'feature_42', 'feature_44', 'feature_00']\nMean absolute error: 0.427\nR2 Score Train: 0.37\nR2 Score Test: 0.25\n\nFinancial Instrument: 1\nFeature Combination: ['feature_06', 'feature_22', 'feature_24', 'feature_37', 'feature_47', 'feature_70', 'feature_30', 'feature_05', 'feature_20', 'feature_14', 'feature_28', 'feature_29', 'feature_08', 'feature_25', 'feature_23', 'feature_67', 'feature_38', 'feature_61', 'feature_78', 'feature_62', 'feature_19', 'feature_36', 'feature_69', 'feature_72', 'feature_65', 'feature_09', 'feature_10', 'feature_11', 'feature_07', 'feature_60', 'feature_56', 'feature_01', 'feature_58', 'feature_31', 'feature_26', 'feature_27', 'feature_04', 'feature_74', 'feature_50', 'feature_33', 'feature_39', 'feature_21', 'feature_73', 'feature_53', 'feature_15', 'feature_32', 'feature_41', 'feature_55', 'feature_02', 'feature_42', 'feature_44', 'feature_03']\nMean absolute error: 0.427\nR2 Score Train: 0.37\nR2 Score Test: 0.25\n\n","output_type":"stream"},{"name":"stderr","text":"Evaluating feature combinations:  50%|█████     | 2/4 [1:08:18<1:06:34, 1997.29s/it]","output_type":"stream"},{"name":"stdout","text":"Financial Instrument: 1\nFeature Combination: ['feature_06', 'feature_22', 'feature_24', 'feature_37', 'feature_47', 'feature_70', 'feature_30', 'feature_05', 'feature_20', 'feature_14', 'feature_28', 'feature_29', 'feature_08', 'feature_25', 'feature_23', 'feature_67', 'feature_38', 'feature_61', 'feature_78', 'feature_62', 'feature_19', 'feature_36', 'feature_69', 'feature_72', 'feature_65', 'feature_09', 'feature_10', 'feature_11', 'feature_07', 'feature_60', 'feature_56', 'feature_01', 'feature_58', 'feature_31', 'feature_26', 'feature_27', 'feature_04', 'feature_74', 'feature_50', 'feature_33', 'feature_39', 'feature_21', 'feature_73', 'feature_53', 'feature_15', 'feature_32', 'feature_41', 'feature_55', 'feature_02', 'feature_42', 'feature_44', 'feature_52']\nMean absolute error: 0.427\nR2 Score Train: 0.37\nR2 Score Test: 0.25\n\nFinancial Instrument: 1\nFeature Combination: ['feature_06', 'feature_22', 'feature_24', 'feature_37', 'feature_47', 'feature_70', 'feature_30', 'feature_05', 'feature_20', 'feature_14', 'feature_28', 'feature_29', 'feature_08', 'feature_25', 'feature_23', 'feature_67', 'feature_38', 'feature_61', 'feature_78', 'feature_62', 'feature_19', 'feature_36', 'feature_69', 'feature_72', 'feature_65', 'feature_09', 'feature_10', 'feature_11', 'feature_07', 'feature_60', 'feature_56', 'feature_01', 'feature_58', 'feature_31', 'feature_26', 'feature_27', 'feature_04', 'feature_74', 'feature_50', 'feature_33', 'feature_39', 'feature_21', 'feature_73', 'feature_53', 'feature_15', 'feature_32', 'feature_41', 'feature_55', 'feature_02', 'feature_42', 'feature_44', 'feature_52', 'feature_00']\nMean absolute error: 0.427\nR2 Score Train: 0.37\nR2 Score Test: 0.25\n\n","output_type":"stream"},{"name":"stderr","text":"Evaluating feature combinations:  75%|███████▌  | 3/4 [1:28:24<27:16, 1636.18s/it]  ","output_type":"stream"},{"name":"stdout","text":"Financial Instrument: 1\nFeature Combination: ['feature_06', 'feature_22', 'feature_24', 'feature_37', 'feature_47', 'feature_70', 'feature_30', 'feature_05', 'feature_20', 'feature_14', 'feature_28', 'feature_29', 'feature_08', 'feature_25', 'feature_23', 'feature_67', 'feature_38', 'feature_61', 'feature_78', 'feature_62', 'feature_19', 'feature_36', 'feature_69', 'feature_72', 'feature_65', 'feature_09', 'feature_10', 'feature_11', 'feature_07', 'feature_60', 'feature_56', 'feature_01', 'feature_58', 'feature_31', 'feature_26', 'feature_27', 'feature_04', 'feature_74', 'feature_50', 'feature_33', 'feature_39', 'feature_21', 'feature_73', 'feature_53', 'feature_15', 'feature_32', 'feature_41', 'feature_55', 'feature_02', 'feature_42', 'feature_44', 'feature_52', 'feature_03']\nMean absolute error: 0.427\nR2 Score Train: 0.37\nR2 Score Test: 0.25\n\n","output_type":"stream"},{"name":"stderr","text":"Evaluating feature combinations: 100%|██████████| 4/4 [1:38:40<00:00, 1480.02s/it]","output_type":"stream"},{"name":"stdout","text":"Financial Instrument: 1\nFeature Combination: ['feature_06', 'feature_22', 'feature_24', 'feature_37', 'feature_47', 'feature_70', 'feature_30', 'feature_05', 'feature_20', 'feature_14', 'feature_28', 'feature_29', 'feature_08', 'feature_25', 'feature_23', 'feature_67', 'feature_38', 'feature_61', 'feature_78', 'feature_62', 'feature_19', 'feature_36', 'feature_69', 'feature_72', 'feature_65', 'feature_09', 'feature_10', 'feature_11', 'feature_07', 'feature_60', 'feature_56', 'feature_01', 'feature_58', 'feature_31', 'feature_26', 'feature_27', 'feature_04', 'feature_74', 'feature_50', 'feature_33', 'feature_39', 'feature_21', 'feature_73', 'feature_53', 'feature_15', 'feature_32', 'feature_41', 'feature_55', 'feature_02', 'feature_42', 'feature_44', 'feature_52', 'feature_03', 'feature_00']\nMean absolute error: 0.428\nR2 Score Train: 0.37\nR2 Score Test: 0.24\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"print(best_features)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T12:12:01.515228Z","iopub.execute_input":"2024-12-18T12:12:01.516058Z","iopub.status.idle":"2024-12-18T12:12:01.533942Z","shell.execute_reply.started":"2024-12-18T12:12:01.515982Z","shell.execute_reply":"2024-12-18T12:12:01.533094Z"}},"outputs":[{"name":"stdout","text":"['feature_06', 'feature_22', 'feature_24', 'feature_37', 'feature_47', 'feature_70', 'feature_30', 'feature_05', 'feature_20', 'feature_14', 'feature_28', 'feature_29', 'feature_08', 'feature_25', 'feature_23', 'feature_67', 'feature_38', 'feature_61', 'feature_78', 'feature_62', 'feature_19', 'feature_36', 'feature_69', 'feature_72', 'feature_65', 'feature_09', 'feature_10', 'feature_11', 'feature_07', 'feature_60', 'feature_56', 'feature_01', 'feature_58', 'feature_31', 'feature_26', 'feature_27', 'feature_04', 'feature_74', 'feature_50', 'feature_33', 'feature_39', 'feature_21', 'feature_73', 'feature_53', 'feature_15', 'feature_32', 'feature_41', 'feature_55', 'feature_02', 'feature_42', 'feature_44', 'feature_52', 'feature_03', 'feature_00']\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"print(best_scores)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T12:12:03.750574Z","iopub.execute_input":"2024-12-18T12:12:03.750936Z","iopub.status.idle":"2024-12-18T12:12:03.765417Z","shell.execute_reply.started":"2024-12-18T12:12:03.750910Z","shell.execute_reply":"2024-12-18T12:12:03.764508Z"}},"outputs":[{"name":"stdout","text":"{'feature_06/feature_22/feature_24/feature_37/feature_47/feature_70/feature_30/feature_05/feature_20/feature_14/feature_28/feature_29/feature_08/feature_25/feature_23/feature_67/feature_38/feature_61/feature_78/feature_62/feature_19/feature_36/feature_69/feature_72/feature_65/feature_09/feature_10/feature_11/feature_07/feature_60/feature_56/feature_01/feature_58/feature_31/feature_26/feature_27/feature_04/feature_74/feature_50': 0.4256425408209205, 'feature_06/feature_22/feature_24/feature_37/feature_47/feature_70/feature_30/feature_05/feature_20/feature_14/feature_28/feature_29/feature_08/feature_25/feature_23/feature_67/feature_38/feature_61/feature_78/feature_62/feature_19/feature_36/feature_69/feature_72/feature_65/feature_09/feature_10/feature_11/feature_07/feature_60/feature_56/feature_01/feature_58/feature_31/feature_26/feature_27/feature_04/feature_74/feature_50/feature_33': 0.4256577751378833, 'feature_06/feature_22/feature_24/feature_37/feature_47/feature_70/feature_30/feature_05/feature_20/feature_14/feature_28/feature_29/feature_08/feature_25/feature_23/feature_67/feature_38/feature_61/feature_78/feature_62/feature_19/feature_36/feature_69/feature_72/feature_65/feature_09/feature_10/feature_11/feature_07/feature_60/feature_56/feature_01/feature_58/feature_31/feature_26/feature_27/feature_04/feature_74/feature_50/feature_33/feature_39': 0.4257329168282258, 'feature_06/feature_22/feature_24/feature_37/feature_47/feature_70/feature_30/feature_05/feature_20/feature_14/feature_28/feature_29/feature_08/feature_25/feature_23/feature_67/feature_38/feature_61/feature_78/feature_62/feature_19/feature_36/feature_69/feature_72/feature_65/feature_09/feature_10/feature_11/feature_07/feature_60/feature_56/feature_01/feature_58/feature_31/feature_26/feature_27/feature_04/feature_74/feature_50/feature_33/feature_39/feature_21': 0.4256889860553527, 'feature_06/feature_22/feature_24/feature_37/feature_47/feature_70/feature_30/feature_05/feature_20/feature_14/feature_28/feature_29/feature_08/feature_25/feature_23/feature_67/feature_38/feature_61/feature_78/feature_62/feature_19/feature_36/feature_69/feature_72/feature_65/feature_09/feature_10/feature_11/feature_07/feature_60/feature_56/feature_01/feature_58/feature_31/feature_26/feature_27/feature_04/feature_74/feature_50/feature_33/feature_39/feature_21/feature_73': 0.42578237985077905, 'feature_06/feature_22/feature_24/feature_37/feature_47/feature_70/feature_30/feature_05/feature_20/feature_14/feature_28/feature_29/feature_08/feature_25/feature_23/feature_67/feature_38/feature_61/feature_78/feature_62/feature_19/feature_36/feature_69/feature_72/feature_65/feature_09/feature_10/feature_11/feature_07/feature_60/feature_56/feature_01/feature_58/feature_31/feature_26/feature_27/feature_04/feature_74/feature_50/feature_33/feature_39/feature_21/feature_73/feature_53': 0.42552762277622824, 'feature_06/feature_22/feature_24/feature_37/feature_47/feature_70/feature_30/feature_05/feature_20/feature_14/feature_28/feature_29/feature_08/feature_25/feature_23/feature_67/feature_38/feature_61/feature_78/feature_62/feature_19/feature_36/feature_69/feature_72/feature_65/feature_09/feature_10/feature_11/feature_07/feature_60/feature_56/feature_01/feature_58/feature_31/feature_26/feature_27/feature_04/feature_74/feature_50/feature_33/feature_39/feature_21/feature_73/feature_53/feature_15': 0.4256377532475385, 'feature_06/feature_22/feature_24/feature_37/feature_47/feature_70/feature_30/feature_05/feature_20/feature_14/feature_28/feature_29/feature_08/feature_25/feature_23/feature_67/feature_38/feature_61/feature_78/feature_62/feature_19/feature_36/feature_69/feature_72/feature_65/feature_09/feature_10/feature_11/feature_07/feature_60/feature_56/feature_01/feature_58/feature_31/feature_26/feature_27/feature_04/feature_74/feature_50/feature_33/feature_39/feature_21/feature_73/feature_53/feature_15/feature_32': 0.42526072871252313, 'feature_06/feature_22/feature_24/feature_37/feature_47/feature_70/feature_30/feature_05/feature_20/feature_14/feature_28/feature_29/feature_08/feature_25/feature_23/feature_67/feature_38/feature_61/feature_78/feature_62/feature_19/feature_36/feature_69/feature_72/feature_65/feature_09/feature_10/feature_11/feature_07/feature_60/feature_56/feature_01/feature_58/feature_31/feature_26/feature_27/feature_04/feature_74/feature_50/feature_33/feature_39/feature_21/feature_73/feature_53/feature_15/feature_32/feature_41': 0.4259224310317046, 'feature_06/feature_22/feature_24/feature_37/feature_47/feature_70/feature_30/feature_05/feature_20/feature_14/feature_28/feature_29/feature_08/feature_25/feature_23/feature_67/feature_38/feature_61/feature_78/feature_62/feature_19/feature_36/feature_69/feature_72/feature_65/feature_09/feature_10/feature_11/feature_07/feature_60/feature_56/feature_01/feature_58/feature_31/feature_26/feature_27/feature_04/feature_74/feature_50/feature_33/feature_39/feature_21/feature_73/feature_53/feature_15/feature_32/feature_41/feature_55': 0.42625380089287435, 'feature_06/feature_22/feature_24/feature_37/feature_47/feature_70/feature_30/feature_05/feature_20/feature_14/feature_28/feature_29/feature_08/feature_25/feature_23/feature_67/feature_38/feature_61/feature_78/feature_62/feature_19/feature_36/feature_69/feature_72/feature_65/feature_09/feature_10/feature_11/feature_07/feature_60/feature_56/feature_01/feature_58/feature_31/feature_26/feature_27/feature_04/feature_74/feature_50/feature_33/feature_39/feature_21/feature_73/feature_53/feature_15/feature_32/feature_41/feature_55/feature_02': 0.426230088333463, 'feature_06/feature_22/feature_24/feature_37/feature_47/feature_70/feature_30/feature_05/feature_20/feature_14/feature_28/feature_29/feature_08/feature_25/feature_23/feature_67/feature_38/feature_61/feature_78/feature_62/feature_19/feature_36/feature_69/feature_72/feature_65/feature_09/feature_10/feature_11/feature_07/feature_60/feature_56/feature_01/feature_58/feature_31/feature_26/feature_27/feature_04/feature_74/feature_50/feature_33/feature_39/feature_21/feature_73/feature_53/feature_15/feature_32/feature_41/feature_55/feature_02/feature_42': 0.42629852915466265, 'feature_06/feature_22/feature_24/feature_37/feature_47/feature_70/feature_30/feature_05/feature_20/feature_14/feature_28/feature_29/feature_08/feature_25/feature_23/feature_67/feature_38/feature_61/feature_78/feature_62/feature_19/feature_36/feature_69/feature_72/feature_65/feature_09/feature_10/feature_11/feature_07/feature_60/feature_56/feature_01/feature_58/feature_31/feature_26/feature_27/feature_04/feature_74/feature_50/feature_33/feature_39/feature_21/feature_73/feature_53/feature_15/feature_32/feature_41/feature_55/feature_02/feature_42/feature_44': 0.4265174525180343, 'feature_06/feature_22/feature_24/feature_37/feature_47/feature_70/feature_30/feature_05/feature_20/feature_14/feature_28/feature_29/feature_08/feature_25/feature_23/feature_67/feature_38/feature_61/feature_78/feature_62/feature_19/feature_36/feature_69/feature_72/feature_65/feature_09/feature_10/feature_11/feature_07/feature_60/feature_56/feature_01/feature_58/feature_31/feature_26/feature_27/feature_04/feature_74/feature_50/feature_33/feature_39/feature_21/feature_73/feature_53/feature_15/feature_32/feature_41/feature_55/feature_02/feature_42/feature_44/feature_52': 0.4268018738695901, 'feature_06/feature_22/feature_24/feature_37/feature_47/feature_70/feature_30/feature_05/feature_20/feature_14/feature_28/feature_29/feature_08/feature_25/feature_23/feature_67/feature_38/feature_61/feature_78/feature_62/feature_19/feature_36/feature_69/feature_72/feature_65/feature_09/feature_10/feature_11/feature_07/feature_60/feature_56/feature_01/feature_58/feature_31/feature_26/feature_27/feature_04/feature_74/feature_50/feature_33/feature_39/feature_21/feature_73/feature_53/feature_15/feature_32/feature_41/feature_55/feature_02/feature_42/feature_44/feature_52/feature_03': 0.42684387999599, 'feature_06/feature_22/feature_24/feature_37/feature_47/feature_70/feature_30/feature_05/feature_20/feature_14/feature_28/feature_29/feature_08/feature_25/feature_23/feature_67/feature_38/feature_61/feature_78/feature_62/feature_19/feature_36/feature_69/feature_72/feature_65/feature_09/feature_10/feature_11/feature_07/feature_60/feature_56/feature_01/feature_58/feature_31/feature_26/feature_27/feature_04/feature_74/feature_50/feature_33/feature_39/feature_21/feature_73/feature_53/feature_15/feature_32/feature_41/feature_55/feature_02/feature_42/feature_44/feature_52/feature_03/feature_00': 0.4275677470295826}\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"import json\nwith open(\"/kaggle/working/features_information_v3.json\", mode=\"w\") as file:\n    json.dump(best_scores, file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T12:12:21.984601Z","iopub.execute_input":"2024-12-18T12:12:21.985053Z","iopub.status.idle":"2024-12-18T12:12:21.992069Z","shell.execute_reply.started":"2024-12-18T12:12:21.985020Z","shell.execute_reply":"2024-12-18T12:12:21.990604Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"best_features = sorted(best_scores.items(), key=lambda x: (x[-1], x[0]), reverse=False)[0] #best feature combination\ncols = best_features[0].split(\"/\")\nprint(cols)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T12:13:13.461759Z","iopub.execute_input":"2024-12-18T12:13:13.462709Z","iopub.status.idle":"2024-12-18T12:13:13.468459Z","shell.execute_reply.started":"2024-12-18T12:13:13.462680Z","shell.execute_reply":"2024-12-18T12:13:13.467463Z"}},"outputs":[{"name":"stdout","text":"['feature_06', 'feature_22', 'feature_24', 'feature_37', 'feature_47', 'feature_70', 'feature_30', 'feature_05', 'feature_20', 'feature_14', 'feature_28', 'feature_29', 'feature_08', 'feature_25', 'feature_23', 'feature_67', 'feature_38', 'feature_61', 'feature_78', 'feature_62', 'feature_19', 'feature_36', 'feature_69', 'feature_72', 'feature_65', 'feature_09', 'feature_10', 'feature_11', 'feature_07', 'feature_60', 'feature_56', 'feature_01', 'feature_58', 'feature_31', 'feature_26', 'feature_27', 'feature_04', 'feature_74', 'feature_50', 'feature_33', 'feature_39', 'feature_21', 'feature_73', 'feature_53', 'feature_15', 'feature_32']\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"sorted(best_scores.items(), key=lambda x: (x[-1], x[0]), reverse=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T12:14:56.322241Z","iopub.execute_input":"2024-12-18T12:14:56.322694Z","iopub.status.idle":"2024-12-18T12:14:56.331023Z","shell.execute_reply.started":"2024-12-18T12:14:56.322657Z","shell.execute_reply":"2024-12-18T12:14:56.330033Z"}},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"[('feature_06/feature_22/feature_24/feature_37/feature_47/feature_70/feature_30/feature_05/feature_20/feature_14/feature_28/feature_29/feature_08/feature_25/feature_23/feature_67/feature_38/feature_61/feature_78/feature_62/feature_19/feature_36/feature_69/feature_72/feature_65/feature_09/feature_10/feature_11/feature_07/feature_60/feature_56/feature_01/feature_58/feature_31/feature_26/feature_27/feature_04/feature_74/feature_50/feature_33/feature_39/feature_21/feature_73/feature_53/feature_15/feature_32',\n  0.42526072871252313),\n ('feature_06/feature_22/feature_24/feature_37/feature_47/feature_70/feature_30/feature_05/feature_20/feature_14/feature_28/feature_29/feature_08/feature_25/feature_23/feature_67/feature_38/feature_61/feature_78/feature_62/feature_19/feature_36/feature_69/feature_72/feature_65/feature_09/feature_10/feature_11/feature_07/feature_60/feature_56/feature_01/feature_58/feature_31/feature_26/feature_27/feature_04/feature_74/feature_50/feature_33/feature_39/feature_21/feature_73/feature_53',\n  0.42552762277622824),\n ('feature_06/feature_22/feature_24/feature_37/feature_47/feature_70/feature_30/feature_05/feature_20/feature_14/feature_28/feature_29/feature_08/feature_25/feature_23/feature_67/feature_38/feature_61/feature_78/feature_62/feature_19/feature_36/feature_69/feature_72/feature_65/feature_09/feature_10/feature_11/feature_07/feature_60/feature_56/feature_01/feature_58/feature_31/feature_26/feature_27/feature_04/feature_74/feature_50/feature_33/feature_39/feature_21/feature_73/feature_53/feature_15',\n  0.4256377532475385),\n ('feature_06/feature_22/feature_24/feature_37/feature_47/feature_70/feature_30/feature_05/feature_20/feature_14/feature_28/feature_29/feature_08/feature_25/feature_23/feature_67/feature_38/feature_61/feature_78/feature_62/feature_19/feature_36/feature_69/feature_72/feature_65/feature_09/feature_10/feature_11/feature_07/feature_60/feature_56/feature_01/feature_58/feature_31/feature_26/feature_27/feature_04/feature_74/feature_50',\n  0.4256425408209205),\n ('feature_06/feature_22/feature_24/feature_37/feature_47/feature_70/feature_30/feature_05/feature_20/feature_14/feature_28/feature_29/feature_08/feature_25/feature_23/feature_67/feature_38/feature_61/feature_78/feature_62/feature_19/feature_36/feature_69/feature_72/feature_65/feature_09/feature_10/feature_11/feature_07/feature_60/feature_56/feature_01/feature_58/feature_31/feature_26/feature_27/feature_04/feature_74/feature_50/feature_33',\n  0.4256577751378833),\n ('feature_06/feature_22/feature_24/feature_37/feature_47/feature_70/feature_30/feature_05/feature_20/feature_14/feature_28/feature_29/feature_08/feature_25/feature_23/feature_67/feature_38/feature_61/feature_78/feature_62/feature_19/feature_36/feature_69/feature_72/feature_65/feature_09/feature_10/feature_11/feature_07/feature_60/feature_56/feature_01/feature_58/feature_31/feature_26/feature_27/feature_04/feature_74/feature_50/feature_33/feature_39/feature_21',\n  0.4256889860553527),\n ('feature_06/feature_22/feature_24/feature_37/feature_47/feature_70/feature_30/feature_05/feature_20/feature_14/feature_28/feature_29/feature_08/feature_25/feature_23/feature_67/feature_38/feature_61/feature_78/feature_62/feature_19/feature_36/feature_69/feature_72/feature_65/feature_09/feature_10/feature_11/feature_07/feature_60/feature_56/feature_01/feature_58/feature_31/feature_26/feature_27/feature_04/feature_74/feature_50/feature_33/feature_39',\n  0.4257329168282258),\n ('feature_06/feature_22/feature_24/feature_37/feature_47/feature_70/feature_30/feature_05/feature_20/feature_14/feature_28/feature_29/feature_08/feature_25/feature_23/feature_67/feature_38/feature_61/feature_78/feature_62/feature_19/feature_36/feature_69/feature_72/feature_65/feature_09/feature_10/feature_11/feature_07/feature_60/feature_56/feature_01/feature_58/feature_31/feature_26/feature_27/feature_04/feature_74/feature_50/feature_33/feature_39/feature_21/feature_73',\n  0.42578237985077905),\n ('feature_06/feature_22/feature_24/feature_37/feature_47/feature_70/feature_30/feature_05/feature_20/feature_14/feature_28/feature_29/feature_08/feature_25/feature_23/feature_67/feature_38/feature_61/feature_78/feature_62/feature_19/feature_36/feature_69/feature_72/feature_65/feature_09/feature_10/feature_11/feature_07/feature_60/feature_56/feature_01/feature_58/feature_31/feature_26/feature_27/feature_04/feature_74/feature_50/feature_33/feature_39/feature_21/feature_73/feature_53/feature_15/feature_32/feature_41',\n  0.4259224310317046),\n ('feature_06/feature_22/feature_24/feature_37/feature_47/feature_70/feature_30/feature_05/feature_20/feature_14/feature_28/feature_29/feature_08/feature_25/feature_23/feature_67/feature_38/feature_61/feature_78/feature_62/feature_19/feature_36/feature_69/feature_72/feature_65/feature_09/feature_10/feature_11/feature_07/feature_60/feature_56/feature_01/feature_58/feature_31/feature_26/feature_27/feature_04/feature_74/feature_50/feature_33/feature_39/feature_21/feature_73/feature_53/feature_15/feature_32/feature_41/feature_55/feature_02',\n  0.426230088333463),\n ('feature_06/feature_22/feature_24/feature_37/feature_47/feature_70/feature_30/feature_05/feature_20/feature_14/feature_28/feature_29/feature_08/feature_25/feature_23/feature_67/feature_38/feature_61/feature_78/feature_62/feature_19/feature_36/feature_69/feature_72/feature_65/feature_09/feature_10/feature_11/feature_07/feature_60/feature_56/feature_01/feature_58/feature_31/feature_26/feature_27/feature_04/feature_74/feature_50/feature_33/feature_39/feature_21/feature_73/feature_53/feature_15/feature_32/feature_41/feature_55',\n  0.42625380089287435),\n ('feature_06/feature_22/feature_24/feature_37/feature_47/feature_70/feature_30/feature_05/feature_20/feature_14/feature_28/feature_29/feature_08/feature_25/feature_23/feature_67/feature_38/feature_61/feature_78/feature_62/feature_19/feature_36/feature_69/feature_72/feature_65/feature_09/feature_10/feature_11/feature_07/feature_60/feature_56/feature_01/feature_58/feature_31/feature_26/feature_27/feature_04/feature_74/feature_50/feature_33/feature_39/feature_21/feature_73/feature_53/feature_15/feature_32/feature_41/feature_55/feature_02/feature_42',\n  0.42629852915466265),\n ('feature_06/feature_22/feature_24/feature_37/feature_47/feature_70/feature_30/feature_05/feature_20/feature_14/feature_28/feature_29/feature_08/feature_25/feature_23/feature_67/feature_38/feature_61/feature_78/feature_62/feature_19/feature_36/feature_69/feature_72/feature_65/feature_09/feature_10/feature_11/feature_07/feature_60/feature_56/feature_01/feature_58/feature_31/feature_26/feature_27/feature_04/feature_74/feature_50/feature_33/feature_39/feature_21/feature_73/feature_53/feature_15/feature_32/feature_41/feature_55/feature_02/feature_42/feature_44',\n  0.4265174525180343),\n ('feature_06/feature_22/feature_24/feature_37/feature_47/feature_70/feature_30/feature_05/feature_20/feature_14/feature_28/feature_29/feature_08/feature_25/feature_23/feature_67/feature_38/feature_61/feature_78/feature_62/feature_19/feature_36/feature_69/feature_72/feature_65/feature_09/feature_10/feature_11/feature_07/feature_60/feature_56/feature_01/feature_58/feature_31/feature_26/feature_27/feature_04/feature_74/feature_50/feature_33/feature_39/feature_21/feature_73/feature_53/feature_15/feature_32/feature_41/feature_55/feature_02/feature_42/feature_44/feature_52',\n  0.4268018738695901),\n ('feature_06/feature_22/feature_24/feature_37/feature_47/feature_70/feature_30/feature_05/feature_20/feature_14/feature_28/feature_29/feature_08/feature_25/feature_23/feature_67/feature_38/feature_61/feature_78/feature_62/feature_19/feature_36/feature_69/feature_72/feature_65/feature_09/feature_10/feature_11/feature_07/feature_60/feature_56/feature_01/feature_58/feature_31/feature_26/feature_27/feature_04/feature_74/feature_50/feature_33/feature_39/feature_21/feature_73/feature_53/feature_15/feature_32/feature_41/feature_55/feature_02/feature_42/feature_44/feature_52/feature_03',\n  0.42684387999599),\n ('feature_06/feature_22/feature_24/feature_37/feature_47/feature_70/feature_30/feature_05/feature_20/feature_14/feature_28/feature_29/feature_08/feature_25/feature_23/feature_67/feature_38/feature_61/feature_78/feature_62/feature_19/feature_36/feature_69/feature_72/feature_65/feature_09/feature_10/feature_11/feature_07/feature_60/feature_56/feature_01/feature_58/feature_31/feature_26/feature_27/feature_04/feature_74/feature_50/feature_33/feature_39/feature_21/feature_73/feature_53/feature_15/feature_32/feature_41/feature_55/feature_02/feature_42/feature_44/feature_52/feature_03/feature_00',\n  0.4275677470295826)]"},"metadata":{}}],"execution_count":28},{"cell_type":"markdown","source":"# Select best hyperparameter","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport glob\nimport polars as pl\nimport lightgbm as lgb\nfrom sklearn.model_selection import KFold, train_test_split\nfrom sklearn.metrics import mean_absolute_error\nimport tqdm\nimport pickle\nfrom sklearn.metrics import r2_score\nfrom sklearnex import patch_sklearn\nimport logging\n\npatch_sklearn()\nlogging.getLogger('sklearnex').setLevel(logging.WARNING)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_path = '/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=*/part-0.parquet'\n\nwith open('/kaggle/input/fillnans/nan_means.p', 'rb') as fp:\n    nan_means = pickle.load(fp)\n\ndef numpy_fillna(arr, fillna_dict, cols):\n    arr_copy = arr.copy()  # Avoid modifying the original array\n    for idx, col in enumerate(cols):\n        arr_copy[:, idx] = np.nan_to_num(arr_copy[:, idx], nan=fillna_dict[col])\n    return arr_copy\n\ndef rolling_window(data, window):\n    size = data.shape[0] - window + 1\n    emb = data.shape[1]\n    inputs = np.lib.stride_tricks.sliding_window_view(data, \n                                                      (window, emb), \n                                                      axis=(0, 1)).reshape(size, window*emb)\n    \n    return inputs\n\ndef evaluate_parameter(path_name, params, hyperparameters, name, cols, fillna, \n                       window=4, n_splits=5, seed=123, shuffle=True, symbol=2):\n    \n    kfold = KFold(n_splits=n_splits, random_state=seed, shuffle=shuffle)\n    scores = []\n    data = get_financial_instrument(path_name, emb_dim=len(cols), cols=cols, instrument=symbol)\n        \n    #Define cross validation\n    for parameter in tqdm.tqdm(hyperparameters, desc=\"Evaluating parameter\"):\n        params[name] = parameter\n        windowed_data, targets = data[:, :-1], data[:, -1]#rolling_window(data, window)\n        windowed_data = numpy_fillna(windowed_data, fillna, cols=cols)\n        \n        error = []\n        r2_train = []\n        r2_test = []\n        for train_ind, test_ind in kfold.split(windowed_data):\n            #Split train data for cross validation\n            X_train, y_train, X_test, y_test = windowed_data[train_ind], targets[train_ind], windowed_data[test_ind], targets[test_ind]\n            model = lgb.LGBMRegressor(**params)\n            model.fit(X_train, y_train, eval_set=[(X_test, y_test)])\n\n            #Generate predictions \n            y_preds = model.predict(X_test)\n            preds = model.predict(X_train)\n            r2_train.append(r2_score(y_train, preds)) #append r2_score\n            r2_test.append(r2_score(y_test, y_preds))\n            error.append(mean_absolute_error(y_test, y_preds)) # append model error      \n        \n        scores.append(np.mean(error))\n        print(f\"\"\"Financial Instrument: {symbol}\\n{name.capitalize()} Hyperparameter: {parameter}\\nMean absolute error: {np.mean(error):.3f}\\nR2 Score Train: {np.mean(r2_train):.2f}\\nR2 Score Test: {np.mean(r2_test):.2f}\"\"\")\n        print()\n        \n    print(f\"Financial Instrument: {symbol}\\nBest {name.capitalize()}: {hyperparameters[np.argmin(scores)]}\\nError: {min(scores)}\")\n    return scores","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T08:26:54.296052Z","iopub.execute_input":"2024-11-25T08:26:54.296918Z","iopub.status.idle":"2024-11-25T08:26:54.329177Z","shell.execute_reply.started":"2024-11-25T08:26:54.296854Z","shell.execute_reply":"2024-11-25T08:26:54.328030Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"params = {\"boosting_type\": 'gbdt',\"num_leaves\": 77, \"max_depth\": 7, \"colsample_bytree\": 0.45, \"learning_rate\": 0.45,\n          'min_child_samples': 20,'min_split_gain': 0.45, \"n_estimators\": 350,\"verbose\": -1, \"metric\": \"rmse\",\n          \"force_col_wise\": True # \"device\": \"gpu\"  # Enable GPU, if available\n         }\n\nhps = list(range(700, 1500, 50))\nscores = evaluate_parameter(path_name=train_path, params=params, cols=cols, fillna=nan_means[2], \n                            window=4, hyperparameters=hps, name=\"n_estimators\", n_splits=5, \n                            shuffle=True, symbol=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T08:29:32.349315Z","iopub.execute_input":"2024-11-25T08:29:32.349787Z","iopub.status.idle":"2024-11-25T11:35:06.358522Z","shell.execute_reply.started":"2024-11-25T08:29:32.349750Z","shell.execute_reply":"2024-11-25T11:35:06.354890Z"}},"outputs":[{"name":"stderr","text":"Evaluating parameter:   6%|▋         | 1/16 [10:25<2:36:22, 625.48s/it]","output_type":"stream"},{"name":"stdout","text":"Financial Instrument: 2\nN_estimators Hyperparameter: 700\nMean absolute error: 0.502\nR2 Score Train: 0.50\nR2 Score Test: 0.37\n\n","output_type":"stream"},{"name":"stderr","text":"Evaluating parameter:  12%|█▎        | 2/16 [20:42<2:24:48, 620.64s/it]","output_type":"stream"},{"name":"stdout","text":"Financial Instrument: 2\nN_estimators Hyperparameter: 750\nMean absolute error: 0.502\nR2 Score Train: 0.50\nR2 Score Test: 0.37\n\n","output_type":"stream"},{"name":"stderr","text":"Evaluating parameter:  19%|█▉        | 3/16 [31:11<2:15:15, 624.24s/it]","output_type":"stream"},{"name":"stdout","text":"Financial Instrument: 2\nN_estimators Hyperparameter: 800\nMean absolute error: 0.502\nR2 Score Train: 0.50\nR2 Score Test: 0.37\n\n","output_type":"stream"},{"name":"stderr","text":"Evaluating parameter:  25%|██▌       | 4/16 [42:06<2:07:18, 636.58s/it]","output_type":"stream"},{"name":"stdout","text":"Financial Instrument: 2\nN_estimators Hyperparameter: 850\nMean absolute error: 0.502\nR2 Score Train: 0.50\nR2 Score Test: 0.37\n\n","output_type":"stream"},{"name":"stderr","text":"Evaluating parameter:  31%|███▏      | 5/16 [52:58<1:57:41, 641.97s/it]","output_type":"stream"},{"name":"stdout","text":"Financial Instrument: 2\nN_estimators Hyperparameter: 900\nMean absolute error: 0.502\nR2 Score Train: 0.50\nR2 Score Test: 0.37\n\n","output_type":"stream"},{"name":"stderr","text":"Evaluating parameter:  38%|███▊      | 6/16 [1:04:03<1:48:18, 649.88s/it]","output_type":"stream"},{"name":"stdout","text":"Financial Instrument: 2\nN_estimators Hyperparameter: 950\nMean absolute error: 0.502\nR2 Score Train: 0.50\nR2 Score Test: 0.37\n\n","output_type":"stream"},{"name":"stderr","text":"Evaluating parameter:  44%|████▍     | 7/16 [1:15:18<1:38:44, 658.24s/it]","output_type":"stream"},{"name":"stdout","text":"Financial Instrument: 2\nN_estimators Hyperparameter: 1000\nMean absolute error: 0.502\nR2 Score Train: 0.50\nR2 Score Test: 0.37\n\n","output_type":"stream"},{"name":"stderr","text":"Evaluating parameter:  50%|█████     | 8/16 [1:26:43<1:28:54, 666.76s/it]","output_type":"stream"},{"name":"stdout","text":"Financial Instrument: 2\nN_estimators Hyperparameter: 1050\nMean absolute error: 0.502\nR2 Score Train: 0.50\nR2 Score Test: 0.37\n\n","output_type":"stream"},{"name":"stderr","text":"Evaluating parameter:  56%|█████▋    | 9/16 [1:38:21<1:18:55, 676.47s/it]","output_type":"stream"},{"name":"stdout","text":"Financial Instrument: 2\nN_estimators Hyperparameter: 1100\nMean absolute error: 0.502\nR2 Score Train: 0.50\nR2 Score Test: 0.37\n\n","output_type":"stream"},{"name":"stderr","text":"Evaluating parameter:  62%|██████▎   | 10/16 [1:50:10<1:08:39, 686.54s/it]","output_type":"stream"},{"name":"stdout","text":"Financial Instrument: 2\nN_estimators Hyperparameter: 1150\nMean absolute error: 0.502\nR2 Score Train: 0.50\nR2 Score Test: 0.37\n\n","output_type":"stream"},{"name":"stderr","text":"Evaluating parameter:  69%|██████▉   | 11/16 [2:02:07<57:58, 695.71s/it]  ","output_type":"stream"},{"name":"stdout","text":"Financial Instrument: 2\nN_estimators Hyperparameter: 1200\nMean absolute error: 0.502\nR2 Score Train: 0.50\nR2 Score Test: 0.37\n\n","output_type":"stream"},{"name":"stderr","text":"Evaluating parameter:  75%|███████▌  | 12/16 [2:14:16<47:03, 705.99s/it]","output_type":"stream"},{"name":"stdout","text":"Financial Instrument: 2\nN_estimators Hyperparameter: 1250\nMean absolute error: 0.502\nR2 Score Train: 0.50\nR2 Score Test: 0.37\n\n","output_type":"stream"},{"name":"stderr","text":"Evaluating parameter:  81%|████████▏ | 13/16 [2:26:37<35:49, 716.44s/it]","output_type":"stream"},{"name":"stdout","text":"Financial Instrument: 2\nN_estimators Hyperparameter: 1300\nMean absolute error: 0.502\nR2 Score Train: 0.50\nR2 Score Test: 0.37\n\n","output_type":"stream"},{"name":"stderr","text":"Evaluating parameter:  88%|████████▊ | 14/16 [2:39:13<24:17, 728.57s/it]","output_type":"stream"},{"name":"stdout","text":"Financial Instrument: 2\nN_estimators Hyperparameter: 1350\nMean absolute error: 0.502\nR2 Score Train: 0.50\nR2 Score Test: 0.37\n\n","output_type":"stream"},{"name":"stderr","text":"Evaluating parameter:  94%|█████████▍| 15/16 [2:51:58<12:19, 739.47s/it]","output_type":"stream"},{"name":"stdout","text":"Financial Instrument: 2\nN_estimators Hyperparameter: 1400\nMean absolute error: 0.502\nR2 Score Train: 0.50\nR2 Score Test: 0.37\n\n","output_type":"stream"},{"name":"stderr","text":"Evaluating parameter: 100%|██████████| 16/16 [3:04:57<00:00, 693.61s/it]","output_type":"stream"},{"name":"stdout","text":"Financial Instrument: 2\nN_estimators Hyperparameter: 1450\nMean absolute error: 0.502\nR2 Score Train: 0.50\nR2 Score Test: 0.37\n\nFinancial Instrument: 2\nBest N_estimators: 700\nError: 0.5018830022376225\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"import json\nwith open(\"/kaggle/input/feature-importance/features_information.json\", mode=\"r\") as file:\n    feature_importance = json.load(file)\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T12:12:41.985284Z","iopub.execute_input":"2024-11-26T12:12:41.986290Z","iopub.status.idle":"2024-11-26T12:12:42.021512Z","shell.execute_reply.started":"2024-11-26T12:12:41.986236Z","shell.execute_reply":"2024-11-26T12:12:42.020461Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"top_k_comb = sorted(feature_importance.items(), key=lambda x: (x[-1], x[0]), reverse=False)[:10] #best feature combination","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T12:12:43.021250Z","iopub.execute_input":"2024-11-26T12:12:43.021980Z","iopub.status.idle":"2024-11-26T12:12:43.027167Z","shell.execute_reply.started":"2024-11-26T12:12:43.021945Z","shell.execute_reply":"2024-11-26T12:12:43.025929Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"cols = top_k_comb[1][0].split(\"/\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T14:30:31.795683Z","iopub.execute_input":"2024-11-26T14:30:31.796189Z","iopub.status.idle":"2024-11-26T14:30:31.801238Z","shell.execute_reply.started":"2024-11-26T14:30:31.796148Z","shell.execute_reply":"2024-11-26T14:30:31.800093Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"print(cols)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T14:30:48.842850Z","iopub.execute_input":"2024-11-26T14:30:48.843836Z","iopub.status.idle":"2024-11-26T14:30:48.848517Z","shell.execute_reply.started":"2024-11-26T14:30:48.843795Z","shell.execute_reply":"2024-11-26T14:30:48.847486Z"}},"outputs":[{"name":"stdout","text":"['feature_06', 'feature_23', 'feature_24', 'feature_60', 'feature_20', 'feature_37', 'feature_05', 'feature_08', 'feature_22', 'feature_70', 'feature_47', 'feature_28', 'feature_61', 'feature_69', 'feature_29', 'feature_25', 'feature_67', 'feature_38', 'feature_72', 'feature_30', 'feature_62', 'feature_77', 'feature_09', 'feature_10', 'feature_11', 'feature_36', 'feature_65', 'feature_07', 'feature_64', 'feature_19', 'feature_18', 'feature_66']\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"# Train Model\n#### Note: The dates in the data are not consecutive, there are skips and 92 cols","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport glob\nimport polars as pl\nimport lightgbm as lgb\nfrom sklearn.model_selection import KFold, train_test_split\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.ensemble import VotingRegressor, RandomForestRegressor\nimport tqdm\nimport pickle\nfrom sklearn.metrics import r2_score\nfrom sklearnex import patch_sklearn\nimport logging\n\npatch_sklearn()\nlogging.getLogger('sklearnex').setLevel(logging.WARNING)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T19:14:52.169098Z","iopub.execute_input":"2024-12-30T19:14:52.169536Z","iopub.status.idle":"2024-12-30T19:14:55.703506Z","shell.execute_reply.started":"2024-12-30T19:14:52.169484Z","shell.execute_reply":"2024-12-30T19:14:55.702160Z"}},"outputs":[{"name":"stderr","text":"Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"train_path = '/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=*/part-0.parquet'\n\nwith open('/kaggle/input/fillnans/nan_means.p', 'rb') as fp:\n    nan_means = pickle.load(fp)\n\ndef numpy_fillna(arr, fillna_dict, cols):\n    arr_copy = arr.copy()  # Avoid modifying the original array\n    for idx, col in enumerate(cols):\n        arr_copy[:, idx] = np.nan_to_num(arr_copy[:, idx], nan=fillna_dict[col])\n    return arr_copy\n\ndef rolling_window(data, window):\n    size = data.shape[0] - window + 1\n    emb = data.shape[1]\n    inputs = np.lib.stride_tricks.sliding_window_view(data, \n                                                      (window, emb), \n                                                      axis=(0, 1)).reshape(size, window*emb)\n    \n    return inputs\n\ndef get_numpy_from_parquet(path, cols, instrument=2):\n    parquet_file = pl.scan_parquet(path)\n    instrument_data = parquet_file.filter(pl.col(\"symbol_id\") == instrument).collect().sort([\"date_id\", \"time_id\"])\n    #instrument_data.select(cols+['responder_6']).to_dummies([\"feature_09\", \"feature_10\", \"feature_11\"], drop_first=True).to_numpy()\n    return instrument_data.select(cols+['responder_6']).to_numpy()\n\ndef get_financial_instrument(path_name, cols, instrument):\n    data = np.empty((0, len(cols)+1), dtype=np.float32)  # Start with an empty array with the correct number of columns\n    for path in glob.glob(path_name):\n        array_to_concat = get_numpy_from_parquet(path=path, cols=cols, instrument=instrument)\n        data = np.vstack((data, array_to_concat))\n    return data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T19:14:55.705261Z","iopub.execute_input":"2024-12-30T19:14:55.706044Z","iopub.status.idle":"2024-12-30T19:14:55.723568Z","shell.execute_reply.started":"2024-12-30T19:14:55.706007Z","shell.execute_reply":"2024-12-30T19:14:55.722281Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"def train_model(path_name, cols, fillna, params, window):\n    models = {}\n    scores = []\n    \n    for symbol in tqdm.tqdm(range(39), desc=\"Model training\"):\n        data = get_financial_instrument(path_name=path_name, cols=cols, instrument=symbol) #np.load(path, allow_pickle=True)\n        windowed_data, targets = data[:, :-1], data[:, -1] #rolling_window(data, window)\n        windowed_data = numpy_fillna(windowed_data, fillna[symbol], cols=cols)\n        windowed_data = rolling_window(windowed_data, window)\n        targets = targets[window-1:]\n        model = lgb.LGBMRegressor(**params)\n        model.fit(windowed_data, targets)\n        models[symbol] = model\n        y_preds = model.predict(windowed_data)\n        score = r2_score(targets, y_preds)\n        scores.append(score)\n        print(f\"Financial Instrument: {symbol}\\nTraining R2 Score: {score:.3f}\")\n    \n    print(f\"Model Training R2 Score across all financial instruments: {np.mean(scores):.3f}\")\n    return models, scores","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T19:14:55.930241Z","iopub.execute_input":"2024-12-30T19:14:55.930653Z","iopub.status.idle":"2024-12-30T19:14:55.938694Z","shell.execute_reply.started":"2024-12-30T19:14:55.930619Z","shell.execute_reply":"2024-12-30T19:14:55.937386Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import json\n\nwith open(\"/kaggle/input/feature-importance/features_information_v3.json\", mode=\"r\") as file:\n    feature_importance = json.load(file)\ntop_k_comb = sorted(feature_importance.items(), key=lambda x: (x[-1], x[0]), reverse=False)[:10] #best feature combination\ncols = top_k_comb[0][0].split(\"/\")\nparams = {\"boosting_type\": 'gbdt',\"num_leaves\": 77, \"max_depth\": 7, \"colsample_bytree\": 0.45, \"learning_rate\": 0.45,\n          'min_child_samples': 20,'min_split_gain': 0.45, \"n_estimators\": 700,\"verbose\": -1, \"metric\": \"rmse\",\n          \"force_col_wise\": True, \"random_state\":123 # \"device\": \"gpu\"  # Enable GPU, if available\n         }\n\ntrain_path = \"/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=*/part-0.parquet\"\nmodel, scores = train_model(train_path, fillna=nan_means, cols=cols, params=params, window=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T19:14:57.176217Z","iopub.execute_input":"2024-12-30T19:14:57.176617Z","execution_failed":"2024-12-30T21:29:59.591Z"}},"outputs":[{"name":"stderr","text":"Model training:   3%|▎         | 1/39 [02:39<1:41:13, 159.82s/it]","output_type":"stream"},{"name":"stdout","text":"Financial Instrument: 0\nTraining R2 Score: 0.494\n","output_type":"stream"},{"name":"stderr","text":"Model training:   5%|▌         | 2/39 [09:55<3:18:44, 322.30s/it]","output_type":"stream"},{"name":"stdout","text":"Financial Instrument: 1\nTraining R2 Score: 0.335\n","output_type":"stream"},{"name":"stderr","text":"Model training:   8%|▊         | 3/39 [22:03<5:04:33, 507.61s/it]","output_type":"stream"},{"name":"stdout","text":"Financial Instrument: 2\nTraining R2 Score: 0.117\n","output_type":"stream"},{"name":"stderr","text":"Model training:  10%|█         | 4/39 [38:49<6:50:41, 704.05s/it]","output_type":"stream"},{"name":"stdout","text":"Financial Instrument: 3\nTraining R2 Score: -0.323\n","output_type":"stream"},{"name":"stderr","text":"Model training:  13%|█▎        | 5/39 [49:26<6:25:18, 679.95s/it]","output_type":"stream"},{"name":"stdout","text":"Financial Instrument: 4\nTraining R2 Score: -0.039\n","output_type":"stream"},{"name":"stderr","text":"Model training:  15%|█▌        | 6/39 [1:09:42<7:54:08, 862.08s/it]","output_type":"stream"},{"name":"stdout","text":"Financial Instrument: 5\nTraining R2 Score: -0.992\n","output_type":"stream"},{"name":"stderr","text":"Model training:  18%|█▊        | 7/39 [1:24:22<7:43:02, 868.19s/it]","output_type":"stream"},{"name":"stdout","text":"Financial Instrument: 6\nTraining R2 Score: -1.862\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"#### Model Training R2 Score across all financial instruments: 0.626 (window)","metadata":{}},{"cell_type":"code","source":"with open('/kaggle/working/models.p', 'wb') as fp:\n    pickle.dump(model, fp, protocol=pickle.HIGHEST_PROTOCOL)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T11:35:14.943926Z","iopub.execute_input":"2024-12-30T11:35:14.944301Z","iopub.status.idle":"2024-12-30T11:35:21.654638Z","shell.execute_reply.started":"2024-12-30T11:35:14.944268Z","shell.execute_reply":"2024-12-30T11:35:21.653541Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"# Deep Learning","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport polars as pl\nimport lightgbm as lgb\nfrom sklearn.model_selection import KFold, train_test_split\nfrom sklearn.metrics import mean_absolute_error\nimport tqdm, pickle, time, logging, glob, pathlib\nfrom sklearn.metrics import r2_score\nfrom sklearnex import patch_sklearn\nimport torch, math\nfrom torch.utils.data import  Dataset, DataLoader\nfrom functools import lru_cache \nimport matplotlib.pyplot as plt\nimport random\n\nroot = pathlib.Path(\"/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet\")\ndef get_paths(nums: list) -> list:\n    return [(root/f\"partition_id={i}/part-0.parquet\") for i in nums] \n\nkfold_paths = get_paths(range(4))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T07:48:59.873681Z","iopub.execute_input":"2025-01-03T07:48:59.874494Z","iopub.status.idle":"2025-01-03T07:49:09.029736Z","shell.execute_reply.started":"2025-01-03T07:48:59.874457Z","shell.execute_reply":"2025-01-03T07:49:09.028795Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import json\nwith open(\"/kaggle/input/feature-importance/features_information_v2.json\", mode=\"r\") as file:\n    feature_importance = json.load(file)\n\nwith open('/kaggle/input/fillnans/nan_means.p', 'rb') as fp:\n    nan_means = pickle.load(fp)\n\ntop_k_comb = sorted(feature_importance.items(), key=lambda x: (x[-1], x[0]), reverse=False)[:10] #best feature combination\ncols = top_k_comb[0][0].split(\"/\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T07:49:09.031313Z","iopub.execute_input":"2025-01-03T07:49:09.031805Z","iopub.status.idle":"2025-01-03T07:49:09.051278Z","shell.execute_reply.started":"2025-01-03T07:49:09.031775Z","shell.execute_reply":"2025-01-03T07:49:09.050669Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"def numpy_fillna(arr, fillna_dict, cols):\n    arr_copy = arr.copy()  # Avoid modifying the original array\n    for idx, col in enumerate(cols):\n        arr_copy[:, idx] = np.nan_to_num(arr_copy[:, idx], nan=fillna_dict[col])\n    return arr_copy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T07:49:09.052352Z","iopub.execute_input":"2025-01-03T07:49:09.052706Z","iopub.status.idle":"2025-01-03T07:49:09.057463Z","shell.execute_reply.started":"2025-01-03T07:49:09.052669Z","shell.execute_reply":"2025-01-03T07:49:09.056510Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"class JaneStreetDatasetV2(Dataset):\n    def __init__(self, paths, cols, frac=None):\n        self.file_mappings = []\n        self.total_rows = 0\n        self.columns = cols\n\n        for path in tqdm.tqdm(paths, desc=\"Loading financial instruments\"):\n            symbol = int(path.parts[-2].split(\"=\")[-1])\n            lazy = pl.scan_parquet(path).select(self.columns+[\"responder_6\"])\n            size = int(lazy.select(pl.len()).collect().item() * frac) if frac else lazy.select(pl.len()).collect().item()\n            np.savez_compressed(f\"preprocessed_symbol_{symbol}.npz\", data=lazy.collect().to_numpy())\n            \n            self.file_mappings.append((symbol, self.total_rows, self.total_rows + size))\n            self.total_rows += size\n\n    @lru_cache(maxsize=10)\n    def _load_file(self, symbol):\n        preprocessed_path = f\"preprocessed_symbol_{symbol}.npz\"\n        data = np.load(preprocessed_path,mmap_mode=\"r\",allow_pickle=True)[\"data\"]\n        inputs = numpy_fillna(\n            data[:, :-1], fillna_dict=nan_means[symbol], cols=self.columns\n        )\n        return inputs, data[:, -1:]\n        \n    def __len__(self):\n        return self.total_rows\n\n    def __getitem__(self, idx):\n        for (symbol, offset, sum_k) in self.file_mappings:\n            if idx < sum_k:\n                idx = idx - offset\n                inputs, target = self._load_file(symbol)\n                return (\n                    torch.tensor(inputs[idx], dtype=torch.float32),\n                    torch.tensor(target[idx], dtype=torch.float32)\n                )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T07:49:09.059520Z","iopub.execute_input":"2025-01-03T07:49:09.059848Z","iopub.status.idle":"2025-01-03T07:49:09.072682Z","shell.execute_reply.started":"2025-01-03T07:49:09.059810Z","shell.execute_reply":"2025-01-03T07:49:09.071950Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def create_dataloader_v2(paths, cfg):\n    dataset = JaneStreetDatasetV2(\n        paths=paths, cols=cfg[\"cols\"], frac=cfg[\"frac\"]\n    )\n    dataloader = DataLoader(dataset=dataset,batch_size=cfg[\"batch_size\"],\n                            shuffle=cfg[\"shuffle\"],num_workers=cfg[\"num_workers\"],\n                            prefetch_factor=cfg[\"prefetch_factor\"],\n                            pin_memory=cfg[\"pin_memory\"],drop_last=cfg[\"drop_last\"]\n                           )\n    return dataloader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T07:49:09.073550Z","iopub.execute_input":"2025-01-03T07:49:09.073824Z","iopub.status.idle":"2025-01-03T07:49:09.083978Z","shell.execute_reply.started":"2025-01-03T07:49:09.073798Z","shell.execute_reply":"2025-01-03T07:49:09.083326Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"cfg = {\n    \"cols\": cols,\n    \"frac\": None,\n    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n    \"batch_size\": 96,\n    \"num_workers\": 1,\n    \"shuffle\": False,\n    \"pin_memory\": True,\n    \"drop_last\": False,\n    \"prefetch_factor\": 2\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T07:50:59.835978Z","iopub.execute_input":"2025-01-03T07:50:59.836795Z","iopub.status.idle":"2025-01-03T07:50:59.841094Z","shell.execute_reply.started":"2025-01-03T07:50:59.836761Z","shell.execute_reply":"2025-01-03T07:50:59.840128Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"def init_weights(m):\n    if isinstance(m, torch.nn.Linear):\n      torch.nn.init.kaiming_normal_(m.weight, a=0, mode='fan_out', nonlinearity='leaky_relu') #torch.nn.init.normal_(m.weight, mean=0.0, std=1/math.sqrt(6))\n      if m.bias is not None:\n        nn.init.constant_(m.bias, 0)\n    elif isinstance(m, torch.nn.Embedding):\n        torch.nn.init.kaiming_normal_(m.weight, a=0, mode='fan_out', nonlinearity='leaky_relu') #torch.nn.init.normal_(m.weight, mean=0.0, std=1/math.sqrt(6))\n\n\nclass LayerNorm(torch.nn.Module):\n    def __init__(self, dim):\n        super().__init__()\n        self.eps = 1e-5\n        self.shift = torch.nn.Parameter(torch.zeros(dim))\n        self.scale = torch.nn.Parameter(torch.ones(dim))\n\n    def forward(self, inp):\n        mean = inp.mean(dim=-1, keepdim=True)\n        var = inp.var(dim=-1, keepdim=True, unbiased=False)\n        inp_norm = (inp - mean)/(torch.sqrt(var)+self.eps)\n\n        return inp_norm + self.shift * self.scale\n\nclass FeedForwardLayer(torch.nn.Module):\n    def __init__(self, dim):\n        super().__init__()\n        self.pos_emb = torch.nn.Embedding(1, dim)\n        self.layer = torch.nn.Sequential(\n            torch.nn.Linear(dim, dim * 4),\n            torch.nn.LeakyReLU(), #torch.nn.GELU(approximate=\"tanh\"),\n            torch.nn.Linear(dim * 4, dim),\n        )\n\n    def forward(self, inp):\n        pos_emb = self.pos_emb(torch.tensor(0, device=inp.device))\n        return self.layer(inp) + pos_emb\n\nclass TransformerBlock(torch.nn.Module):\n    def __init__(self, cfg):\n        super().__init__()\n        self.forward_layer = FeedForwardLayer(cfg[\"n_features\"])\n        self.norm = LayerNorm(cfg[\"n_features\"])\n        self.dropout = torch.nn.Dropout(cfg[\"drop_rate\"])\n\n    def forward(self, inp):\n        shortcut = inp\n        inp = self.norm(inp)\n        inp = self.forward_layer(inp)/0.1\n        out = self.dropout(inp)\n        return out + shortcut","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T07:51:01.255787Z","iopub.execute_input":"2025-01-03T07:51:01.256652Z","iopub.status.idle":"2025-01-03T07:51:01.266493Z","shell.execute_reply.started":"2025-01-03T07:51:01.256611Z","shell.execute_reply":"2025-01-03T07:51:01.265556Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"class JaneStreetModelV2(torch.nn.Module):\n    def __init__(self, cfg):\n        super().__init__()\n        self.blocks = torch.nn.Sequential(\n            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n        )\n        self.norm =  LayerNorm(cfg[\"n_features\"])\n        self.final_norm = LayerNorm(cfg[\"n_features\"])\n        self.out_proj = torch.nn.Linear(cfg[\"n_features\"], 1, bias=False)\n\n    def forward(self, inp):\n        inp = self.blocks(self.norm(inp))\n        inp = self.final_norm(inp)\n\n        return self.out_proj(inp)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T07:51:03.654027Z","iopub.execute_input":"2025-01-03T07:51:03.654416Z","iopub.status.idle":"2025-01-03T07:51:03.660183Z","shell.execute_reply.started":"2025-01-03T07:51:03.654385Z","shell.execute_reply":"2025-01-03T07:51:03.659257Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"MODEL_CONFIG = {\n    \"n_features\": len(cfg[\"cols\"]),\n    \"n_layers\": 6,\n    \"drop_rate\": 0.1\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T07:51:04.053227Z","iopub.execute_input":"2025-01-03T07:51:04.053581Z","iopub.status.idle":"2025-01-03T07:51:04.057840Z","shell.execute_reply.started":"2025-01-03T07:51:04.053549Z","shell.execute_reply":"2025-01-03T07:51:04.056904Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"def calc_loss_batch(inp, targets, device):\n    inp = inp.to(device)\n    targets = targets.to(device)\n    outputs = model(inp)\n    loss = torch.nn.functional.l1_loss(outputs, targets)\n\n    return loss.item(), outputs\n\ndef evaluate_model(val_loader, num_batch, device, choices):\n    total_loss = 0\n    for i, (inp, targets) in enumerate(val_loader):\n        if i < num_batch:\n            with torch.no_grad():\n                loss, outputs = calc_loss_batch(\n                    inp=inp, targets=targets, device=device\n                )\n            total_loss += loss\n        else:\n            break\n    outputs = outputs.flatten().detach().cpu().numpy()\n    targets = targets.flatten().detach().cpu().numpy()\n    print(f\"Sample predictions range: (max:{max(outputs)}, min:{min(outputs)}) - Targets range: (max:{max(targets)}, min:{min(targets)})\")\n    return total_loss/num_batch\n\ndef train_epoch(train_loader, device, freq, choices, global_step,\n                half_loops, start_lr, min_lr):\n    last_loss, running_loss = 0., 0.\n    time_step = 0.\n    scores = []\n    total_len = len(train_loader)\n\n    for batch, (input_batch, targets_batch) in enumerate(train_loader):\n        #compute time per step\n        start_time = time.time()\n        #transfer data to device\n        input_batch = input_batch.to(device)\n        targets_batch = targets_batch.to(device)\n        #zero gradients for every batch\n        optimizer.zero_grad()\n        global_step += 1\n        if global_step <= half_loops:\n            # Apply cosine decay to halfway point\n            optimizer.param_groups[0][\"lr\"] = min_lr + 0.5 * (start_lr - min_lr) * (1 + math.cos(math.pi * global_step / half_loops))\n        else:\n            # Maintain the minimum learning rate beyond halfway point\n            optimizer.param_groups[0][\"lr\"] = min_lr\n        outputs = model(input_batch)\n        loss = torch.nn.functional.smooth_l1_loss(outputs, targets_batch)\n        loss.backward()\n        optimizer.step()\n        time_step += time.time() - start_time\n\n        running_loss += loss.item()\n        if batch % freq == freq-1:\n            last_loss = running_loss / freq\n            print(f\"Batch {batch}/{total_len} - {time_step/freq:.3f}s/step - loss: {last_loss} - lr: {optimizer.param_groups[0]['lr']}\")\n            # print(f\"Model prediction: {outputs[choices].flatten().detach().cpu().numpy()} - Target: {targets_batch[choices].flatten().cpu().numpy()} \")\n            running_loss = 0.\n            time_step = 0.\n            scores.append(last_loss)\n\n    return np.mean(scores), global_step\n\ndef train_model(epochs, train_loader, freq, device, frac=4, min_lr=5e-4, num_batch=None, val_loader=None):\n\n    global_step = -1\n    total_loops = len(train_loader) * epochs\n    half_loops = total_loops // frac\n    start_lr = optimizer.param_groups[0][\"lr\"]\n    history = {\"loss\": []}\n\n    choices = random.choices(range(cfg[\"batch_size\"]-10),k=3)\n    for i in range(epochs):\n        print(f\"Epoch {i+1}/{epochs}\")\n        #set model to training mode\n        model.train(True)\n        #train model\n        avg_loss, global_step = train_epoch(\n            train_loader=train_loader, device=device, freq=freq, choices=choices,\n            global_step=global_step, half_loops=half_loops, start_lr=start_lr, min_lr=min_lr\n        )\n\n        if val_loader:\n            model.eval()\n            avg_vloss = evaluate_model(\n                val_loader=val_loader, num_batch=num_batch, choices=choices, device=device\n            )\n            history[\"val_loss\"] = history.get('val_loss', []) + [avg_vloss]\n            print(f\"train loss: {avg_loss} - val loss: {avg_vloss}\")\n        else:\n            print(f\"train loss: {avg_loss}\")\n        history[\"loss\"].append(avg_loss)\n\n    return history","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T07:51:06.436483Z","iopub.execute_input":"2025-01-03T07:51:06.437306Z","iopub.status.idle":"2025-01-03T07:51:06.450134Z","shell.execute_reply.started":"2025-01-03T07:51:06.437271Z","shell.execute_reply":"2025-01-03T07:51:06.449333Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"kfold_paths = get_paths(range(4))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T07:51:07.677699Z","iopub.execute_input":"2025-01-03T07:51:07.678462Z","iopub.status.idle":"2025-01-03T07:51:07.682410Z","shell.execute_reply.started":"2025-01-03T07:51:07.678420Z","shell.execute_reply":"2025-01-03T07:51:07.681481Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"cfg[\"frac\"] = 0.1\nfolds = 3\nkfold_paths = np.array(kfold_paths)\nkfold = KFold(n_splits=folds, random_state=123, shuffle=True)\nhistorys = {\"val_loss\": [], \"loss\": [], \"val_score\":[], \"score\":[]}\nfor train_path, test_path in kfold.split(kfold_paths):\n    train = create_dataloader_v2(kfold_paths[train_path], cfg)\n    test = create_dataloader_v2(kfold_paths[test_path], cfg)\n\n    torch.manual_seed(11) #11 #32\n    model = JaneStreetModelV2(MODEL_CONFIG)\n    # model.apply(init_weights)\n    model.to(cfg[\"device\"])\n    optimizer = torch.optim.AdamW(\n        model.parameters(), lr=5e-3, weight_decay=1e-4\n    )\n    num_epochs = 5\n    history = train_model(epochs=num_epochs, train_loader=train, val_loader=test, frac=1, \n                          freq=len(train)//2, min_lr=3e-4, num_batch=len(test), device=cfg[\"device\"])\n\n    print(f'Epochs({num_epochs}): Train error: {np.mean(history[\"loss\"]):.7f} - Validation Error: {np.mean(history[\"val_loss\"]):.7f}')\n    print()\n    historys[\"val_score\"].append(history[\"val_loss\"][-1])\n    historys[\"score\"].append(history[\"loss\"][-1])\n    historys[\"val_loss\"].append(history[\"val_loss\"])\n    historys[\"loss\"].append(history[\"loss\"])\n\nprint(f\"\"\"KFold Cross Validation: {folds} - Mean Train error: {np.mean(historys[\"score\"]):.7f} - Mean Validation error: {np.mean(historys[\"val_score\"]):.7f}\"\"\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T15:07:01.247311Z","iopub.execute_input":"2024-12-29T15:07:01.247829Z","iopub.status.idle":"2024-12-29T16:14:37.183040Z","shell.execute_reply.started":"2024-12-29T15:07:01.247790Z","shell.execute_reply":"2024-12-29T16:14:37.180589Z"}},"outputs":[{"name":"stderr","text":"Loading financial instruments: 100%|██████████| 2/2 [00:35<00:00, 17.69s/it]\nLoading financial instruments: 100%|██████████| 2/2 [00:35<00:00, 17.66s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Batch 3041/6085 - 0.020s/step - loss: 0.3392965414568679 - lr: 0.004885095262720301\nBatch 6083/6085 - 0.020s/step - loss: 0.4026450035195947 - lr: 0.0045514751529218914\nSample predictions range: (max:-0.005906291306018829, min:-0.012672403827309608) - Targets range: (max:3.612952470779419, min:-2.362999439239502)\ntrain loss: 0.3709707724882313 - val loss: 0.6780029000867392\nEpoch 2/5\nBatch 3041/6085 - 0.021s/step - loss: 0.3367704408767435 - lr: 0.004031589792924509\nBatch 6083/6085 - 0.019s/step - loss: 0.4025800101370854 - lr: 0.0033766514763024125\nSample predictions range: (max:0.006581532768905163, min:-0.03425678610801697) - Targets range: (max:3.612952470779419, min:-2.362999439239502)\ntrain loss: 0.36967522550691445 - val loss: 0.6782650322873811\nEpoch 3/5\nBatch 3041/6085 - 0.021s/step - loss: 0.336541765247013 - lr: 0.0026503639807414826\nBatch 6083/6085 - 0.020s/step - loss: 0.4024213417760788 - lr: 0.0019242716337107002\nSample predictions range: (max:-0.006083087995648384, min:-0.02181599847972393) - Targets range: (max:3.612952470779419, min:-2.362999439239502)\ntrain loss: 0.3694815535115459 - val loss: 0.6780332062987314\nEpoch 4/5\nBatch 3041/6085 - 0.019s/step - loss: 0.33616858721146803 - lr: 0.0012689991402864617\nBatch 6083/6085 - 0.019s/step - loss: 0.4020559429163499 - lr: 0.0007490953604415673\nSample predictions range: (max:-0.008585542440414429, min:-0.017122266814112663) - Targets range: (max:3.612952470779419, min:-2.362999439239502)\ntrain loss: 0.36911226506390893 - val loss: 0.6779599361529577\nEpoch 5/5\nBatch 3041/6085 - 0.019s/step - loss: 0.3358571642065601 - lr: 0.00041512968974918613\nBatch 6083/6085 - 0.019s/step - loss: 0.40168518484015947 - lr: 0.00030000005011138745\nSample predictions range: (max:-0.009172717109322548, min:-0.023733293637633324) - Targets range: (max:3.612952470779419, min:-2.362999439239502)\ntrain loss: 0.3687711745233598 - val loss: 0.6779525635419068\nEpochs(5): Train error: 0.3696022 - Validation Error: 0.6780427\n\n","output_type":"stream"},{"name":"stderr","text":"Loading financial instruments: 100%|██████████| 3/3 [00:53<00:00, 17.69s/it]\nLoading financial instruments: 100%|██████████| 1/1 [00:16<00:00, 16.01s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Batch 4685/9373 - 0.020s/step - loss: 0.3480450748209573 - lr: 0.004885055822147457\nBatch 9371/9373 - 0.019s/step - loss: 0.4006757119623209 - lr: 0.004551375109805974\nSample predictions range: (max:0.033861614763736725, min:0.030985042452812195) - Targets range: (max:1.5336878299713135, min:-2.151968240737915)\ntrain loss: 0.37436039339163907 - val loss: 0.6515785204724732\nEpoch 2/5\nBatch 4685/9373 - 0.020s/step - loss: 0.34585671072346413 - lr: 0.004031486505145601\nBatch 9371/9373 - 0.020s/step - loss: 0.40040510519563904 - lr: 0.0033764895741494423\nSample predictions range: (max:0.023781605064868927, min:0.022822190076112747) - Targets range: (max:1.5336878299713135, min:-2.151968240737915)\ntrain loss: 0.3731309079595516 - val loss: 0.650973986456914\nEpoch 3/5\nBatch 4685/9373 - 0.019s/step - loss: 0.34571542999040566 - lr: 0.0026502362981774296\nBatch 9371/9373 - 0.018s/step - loss: 0.4002550813839288 - lr: 0.001924109713640261\nSample predictions range: (max:0.00827879924327135, min:0.006095058284699917) - Targets range: (max:1.5336878299713135, min:-2.151968240737915)\ntrain loss: 0.3729852556871672 - val loss: 0.6501689992314695\nEpoch 4/5\nBatch 4685/9373 - 0.019s/step - loss: 0.3454826760868575 - lr: 0.0012688958333369614\nBatch 9371/9373 - 0.019s/step - loss: 0.40010417865571773 - lr: 0.0007489952704171056\nSample predictions range: (max:-0.00072612235089764, min:-0.002149727428331971) - Targets range: (max:1.5336878299713135, min:-2.151968240737915)\ntrain loss: 0.3727934273712876 - val loss: 0.649868049148233\nEpoch 5/5\nBatch 4685/9373 - 0.019s/step - loss: 0.34530279942215003 - lr: 0.0004150902181576739\nBatch 9371/9373 - 0.019s/step - loss: 0.40001319547398856 - lr: 0.00030000002112031337\nSample predictions range: (max:-0.0031591649167239666, min:-0.011796282604336739) - Targets range: (max:1.5336878299713135, min:-2.151968240737915)\ntrain loss: 0.37265799744806927 - val loss: 0.6496651532647342\nEpochs(5): Train error: 0.3731856 - Validation Error: 0.6504509\n\n","output_type":"stream"},{"name":"stderr","text":"Loading financial instruments: 100%|██████████| 3/3 [00:52<00:00, 17.65s/it]\nLoading financial instruments: 100%|██████████| 1/1 [00:20<00:00, 20.09s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Batch 4564/9131 - 0.019s/step - loss: 0.31943855316919834 - lr: 0.004885057756802568\nBatch 9129/9131 - 0.019s/step - loss: 0.3870529151359432 - lr: 0.004551380017004218\nSample predictions range: (max:0.02684212103486061, min:0.025023117661476135) - Targets range: (max:2.2443041801452637, min:-3.0326690673828125)\ntrain loss: 0.35324573415257077 - val loss: 0.7287970761498895\nEpoch 2/5\nBatch 4564/9131 - 0.019s/step - loss: 0.3172455501976257 - lr: 0.004031491571352114\nBatch 9129/9131 - 0.020s/step - loss: 0.3868061108031154 - lr: 0.003376497515297334\nSample predictions range: (max:0.017521582543849945, min:0.016856638714671135) - Targets range: (max:2.2443041801452637, min:-3.0326690673828125)\ntrain loss: 0.3520258305003705 - val loss: 0.7283092429331597\nEpoch 3/5\nBatch 4564/9131 - 0.018s/step - loss: 0.31695883865340696 - lr: 0.0026502425608166524\nBatch 9129/9131 - 0.019s/step - loss: 0.38665210187174015 - lr: 0.0019241176554892156\nSample predictions range: (max:0.008396630175411701, min:0.005625120364129543) - Targets range: (max:2.2443041801452637, min:-3.0326690673828125)\ntrain loss: 0.3518054702625736 - val loss: 0.7278104760647574\nEpoch 4/5\nBatch 4564/9131 - 0.019s/step - loss: 0.3167564537128289 - lr: 0.0012689009002935692\nBatch 9129/9131 - 0.020s/step - loss: 0.3864851981821712 - lr: 0.0007490001794507562\nSample predictions range: (max:0.0011377341579645872, min:0.000663800397887826) - Targets range: (max:2.2443041801452637, min:-3.0326690673828125)\ntrain loss: 0.35162082594750005 - val loss: 0.72761541205622\nEpoch 5/5\nBatch 4564/9131 - 0.022s/step - loss: 0.3164507520748231 - lr: 0.00041509215402646226\nBatch 9129/9131 - 0.022s/step - loss: 0.38634625549865775 - lr: 0.0003000000222546571\nSample predictions range: (max:0.010217640548944473, min:-0.005672445520758629) - Targets range: (max:2.2443041801452637, min:-3.0326690673828125)\ntrain loss: 0.3513985037867404 - val loss: 0.7271953953239318\nEpochs(5): Train error: 0.3520193 - Validation Error: 0.7279455\n\nKFold Cross Validation: 3 - Mean Train error: 0.3642759 - Mean Validation error: 0.6849377\n","output_type":"stream"}],"execution_count":76},{"cell_type":"markdown","source":"KFold Cross Validation: 3 - Mean Squared error: 0.6846301 (96 batch size, 6 layers, 0.1 droprate)","metadata":{}},{"cell_type":"code","source":"torch.manual_seed(11) #11 #32\npaths = glob.glob(str(root/\"partition_id=*/part-0.parquet\"))\npaths = [pathlib.Path(path) for path in paths]\ndata_loader = create_dataloader_v2(paths, cfg)\nmodel = JaneStreetModelV2(MODEL_CONFIG)\nmodel.to(cfg[\"device\"])\noptimizer = torch.optim.AdamW(\n    model.parameters(), lr=5e-3, weight_decay=1e-4\n)\nnum_epochs = 5\nhistory = train_model(epochs=num_epochs, train_loader=data_loader, frac=1, min_lr=3e-4,\n                      freq=len(data_loader)//50, device=cfg[\"device\"])\n\nprint(f\"\"\"Epochs: {num_epochs}\\nTrain error: {np.mean(history[\"loss\"]):.7f}\"\"\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T07:51:13.733632Z","iopub.execute_input":"2025-01-03T07:51:13.734155Z","iopub.status.idle":"2025-01-03T14:54:17.492597Z","shell.execute_reply.started":"2025-01-03T07:51:13.734120Z","shell.execute_reply":"2025-01-03T14:54:17.491523Z"}},"outputs":[{"name":"stderr","text":"Loading financial instruments: 100%|██████████| 10/10 [03:43<00:00, 22.36s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/5\nBatch 9817/490910 - 0.010s/step - loss: 0.2726002912890613 - lr: 0.0049998144992312345\nBatch 19635/490910 - 0.010s/step - loss: 0.2631366495103749 - lr: 0.004999257950632049\nBatch 29453/490910 - 0.010s/step - loss: 0.3321751893886355 - lr: 0.004998330442082415\nBatch 39271/490910 - 0.010s/step - loss: 0.5015549261607101 - lr: 0.004997032120040717\nBatch 49089/490910 - 0.010s/step - loss: 0.19788664134693962 - lr: 0.004995363189518705\nBatch 58907/490910 - 0.010s/step - loss: 0.25735669867829003 - lr: 0.004993323914049116\nBatch 68725/490910 - 0.010s/step - loss: 0.32372269358479866 - lr: 0.004990914615644069\nBatch 78543/490910 - 0.010s/step - loss: 0.1994130615659861 - lr: 0.004988135674744213\nBatch 88361/490910 - 0.010s/step - loss: 0.3652098274196504 - lr: 0.00498498753015865\nBatch 98179/490910 - 0.010s/step - loss: 0.2561894743387426 - lr: 0.004981470678995655\nBatch 107997/490910 - 0.010s/step - loss: 0.27337701796986774 - lr: 0.004977585676584168\nBatch 117815/490910 - 0.010s/step - loss: 0.28493340008786444 - lr: 0.004973333136386113\nBatch 127633/490910 - 0.010s/step - loss: 0.1920993203914977 - lr: 0.0049687137298995284\nBatch 137451/490910 - 0.010s/step - loss: 0.2023761826084521 - lr: 0.004963728186552528\nBatch 147269/490910 - 0.010s/step - loss: 0.28014678145645167 - lr: 0.004958377293588129\nBatch 157087/490910 - 0.010s/step - loss: 0.297698182984238 - lr: 0.004952661895939936\nBatch 166905/490910 - 0.010s/step - loss: 0.36622694780699866 - lr: 0.004946582896098724\nBatch 176723/490910 - 0.010s/step - loss: 0.40930598205113683 - lr: 0.004940141253969928\nBatch 186541/490910 - 0.010s/step - loss: 0.3932941840400202 - lr: 0.004933337986722075\nBatch 196359/490910 - 0.010s/step - loss: 0.3128341494796293 - lr: 0.004926174168626163\nBatch 206177/490910 - 0.010s/step - loss: 0.3688738135785816 - lr: 0.0049186509308860255\nBatch 215995/490910 - 0.010s/step - loss: 0.3397987506720986 - lr: 0.004910769461459717\nBatch 225813/490910 - 0.010s/step - loss: 0.30481792298695964 - lr: 0.004902531004871921\nBatch 235631/490910 - 0.010s/step - loss: 0.24240810410809216 - lr: 0.004893936862017435\nBatch 245449/490910 - 0.010s/step - loss: 0.33694180654011624 - lr: 0.004884988389955753\nBatch 255267/490910 - 0.010s/step - loss: 0.3719028725906718 - lr: 0.004875687001696782\nBatch 265085/490910 - 0.010s/step - loss: 0.2987221234805698 - lr: 0.004866034165977712\nBatch 274903/490910 - 0.010s/step - loss: 0.2804089179285285 - lr: 0.004856031407031104\nBatch 284721/490910 - 0.010s/step - loss: 0.277889248322719 - lr: 0.0048456803043442015\nBatch 294539/490910 - 0.010s/step - loss: 0.25233322328283253 - lr: 0.004834982492409521\nBatch 304357/490910 - 0.010s/step - loss: 0.18205468512006842 - lr: 0.004823939660466758\nBatch 314175/490910 - 0.010s/step - loss: 0.29531486034598203 - lr: 0.004812553552236046\nBatch 323993/490910 - 0.010s/step - loss: 0.3164257201947421 - lr: 0.004800825965642618\nBatch 333811/490910 - 0.010s/step - loss: 0.297532458312128 - lr: 0.0047887587525328994\nBatch 343629/490910 - 0.010s/step - loss: 0.2883503902646134 - lr: 0.004776353818382098\nBatch 353447/490910 - 0.010s/step - loss: 0.24183726324650492 - lr: 0.004763613121993314\nBatch 363265/490910 - 0.010s/step - loss: 0.37657992731469436 - lr: 0.0047505386751882355\nBatch 373083/490910 - 0.010s/step - loss: 0.34559621235416826 - lr: 0.004737132542489468\nBatch 382901/490910 - 0.010s/step - loss: 0.16251560240505117 - lr: 0.004723396840794528\nBatch 392719/490910 - 0.010s/step - loss: 0.18888843205204792 - lr: 0.004709333739041575\nBatch 402537/490910 - 0.010s/step - loss: 0.22575643243555366 - lr: 0.00469494545786693\nBatch 412355/490910 - 0.010s/step - loss: 0.25846258589641596 - lr: 0.004680234269254421\nBatch 422173/490910 - 0.010s/step - loss: 0.2680297035630584 - lr: 0.004665202496176626\nBatch 431991/490910 - 0.010s/step - loss: 0.2380409486376297 - lr: 0.004649852512228064\nBatch 441809/490910 - 0.010s/step - loss: 0.25329537570581256 - lr: 0.004634186741250394\nBatch 451627/490910 - 0.010s/step - loss: 0.24630061563170413 - lr: 0.004618207656949672\nBatch 461445/490910 - 0.010s/step - loss: 0.3038834172657094 - lr: 0.004601917782505748\nBatch 471263/490910 - 0.010s/step - loss: 0.24075798102346985 - lr: 0.004585319690173839\nBatch 481081/490910 - 0.010s/step - loss: 0.23638881769856177 - lr: 0.0045684160008783534\nBatch 490899/490910 - 0.010s/step - loss: 0.21847618307882644 - lr: 0.004551209383799041\ntrain loss: 0.28480243996394516\nEpoch 2/5\nBatch 9817/490910 - 0.010s/step - loss: 0.2714717079814919 - lr: 0.004533684572483247\nBatch 19635/490910 - 0.010s/step - loss: 0.26263635265941615 - lr: 0.0045158799967469744\nBatch 29453/490910 - 0.010s/step - loss: 0.3317472256498476 - lr: 0.004497780788932964\nBatch 39271/490910 - 0.010s/step - loss: 0.5011972830507333 - lr: 0.004479389806999505\nBatch 49089/490910 - 0.010s/step - loss: 0.19773602795284972 - lr: 0.004460709954977525\nBatch 58907/490910 - 0.010s/step - loss: 0.25675262851679664 - lr: 0.004441744182512032\nBatch 68725/490910 - 0.010s/step - loss: 0.32332047456118473 - lr: 0.00442249548439634\nBatch 78543/490910 - 0.010s/step - loss: 0.19920779415240283 - lr: 0.004402966900099192\nBatch 88361/490910 - 0.010s/step - loss: 0.3643548327641754 - lr: 0.004383161513284796\nBatch 98179/490910 - 0.010s/step - loss: 0.2560307178177724 - lr: 0.004363082451325907\nBatch 107997/490910 - 0.010s/step - loss: 0.2727227947014665 - lr: 0.00434273288481\nBatch 117815/490910 - 0.010s/step - loss: 0.2847010364517324 - lr: 0.004322116027038612\nBatch 127633/490910 - 0.010s/step - loss: 0.19193030132846267 - lr: 0.004301235133519949\nBatch 137451/490910 - 0.010s/step - loss: 0.2020848851850536 - lr: 0.004280093501454827\nBatch 147269/490910 - 0.010s/step - loss: 0.2799893775455886 - lr: 0.004258694469216017\nBatch 157087/490910 - 0.010s/step - loss: 0.2976596962067115 - lr: 0.004237041415821112\nBatch 166905/490910 - 0.010s/step - loss: 0.3658680358021711 - lr: 0.004215137760398951\nBatch 176723/490910 - 0.010s/step - loss: 0.40905708869144 - lr: 0.0041929869616497304\nBatch 186541/490910 - 0.010s/step - loss: 0.393126579093464 - lr: 0.004170592517298849\nBatch 196359/490910 - 0.010s/step - loss: 0.3126439621554789 - lr: 0.004147957963544605\nBatch 206177/490910 - 0.010s/step - loss: 0.36871422829178924 - lr: 0.004125086874499811\nBatch 215995/490910 - 0.010s/step - loss: 0.33963214727238134 - lr: 0.00410198286162742\nBatch 225813/490910 - 0.010s/step - loss: 0.3046930178197017 - lr: 0.004078649573170262\nBatch 235631/490910 - 0.010s/step - loss: 0.24231491502913965 - lr: 0.004055090693574962\nBatch 245449/490910 - 0.010s/step - loss: 0.33676244209065764 - lr: 0.00403130994291015\nBatch 255267/490910 - 0.010s/step - loss: 0.371879493408277 - lr: 0.004007311076279044\nBatch 265085/490910 - 0.010s/step - loss: 0.2984250456361864 - lr: 0.003983097883226498\nBatch 274903/490910 - 0.010s/step - loss: 0.280263330610414 - lr: 0.003958674187140612\nBatch 284721/490910 - 0.010s/step - loss: 0.2778925763949278 - lr: 0.0039340438446490026\nBatch 294539/490910 - 0.010s/step - loss: 0.2522163649360361 - lr: 0.003909210745009819\nBatch 304357/490910 - 0.010s/step - loss: 0.18196796329419193 - lr: 0.0038841788094976103\nBatch 314175/490910 - 0.010s/step - loss: 0.2951309321082811 - lr: 0.0038589519907841377\nBatch 323993/490910 - 0.010s/step - loss: 0.31612140611168865 - lr: 0.003833534272314223\nBatch 333811/490910 - 0.010s/step - loss: 0.29734181499611045 - lr: 0.003807929667676744\nBatch 343629/490910 - 0.010s/step - loss: 0.28823746175068965 - lr: 0.0037821422199708706\nBatch 353447/490910 - 0.010s/step - loss: 0.24175094781492043 - lr: 0.003756176001167634\nBatch 363265/490910 - 0.010s/step - loss: 0.3764194975675206 - lr: 0.0037300351114669473\nBatch 373083/490910 - 0.010s/step - loss: 0.34539837775083004 - lr: 0.0037037236786501564\nBatch 382901/490910 - 0.010s/step - loss: 0.16230793727882833 - lr: 0.0036772458574282465\nBatch 392719/490910 - 0.010s/step - loss: 0.18870624314680964 - lr: 0.0036506058287857903\nBatch 402537/490910 - 0.010s/step - loss: 0.22546323856771794 - lr: 0.0036238077993207486\nBatch 412355/490910 - 0.010s/step - loss: 0.25836016388067795 - lr: 0.0035968560005802275\nBatch 422173/490910 - 0.010s/step - loss: 0.2680284513468308 - lr: 0.0035697546883922946\nBatch 431991/490910 - 0.010s/step - loss: 0.23788227095712794 - lr: 0.003542508142193964\nBatch 441809/490910 - 0.010s/step - loss: 0.2532370778765961 - lr: 0.003515120664355446\nBatch 451627/490910 - 0.010s/step - loss: 0.24626345728499555 - lr: 0.0034875965795007876\nBatch 461445/490910 - 0.010s/step - loss: 0.3034950305109574 - lr: 0.0034599402338249857\nBatch 471263/490910 - 0.010s/step - loss: 0.2405994142927222 - lr: 0.003432155994407705\nBatch 481081/490910 - 0.010s/step - loss: 0.23634780366501126 - lr: 0.0034042482485236903\nBatch 490899/490910 - 0.010s/step - loss: 0.2183614382749876 - lr: 0.003376221402949996\ntrain loss: 0.28456906584470487\nEpoch 3/5\nBatch 9817/490910 - 0.010s/step - loss: 0.27135155282696083 - lr: 0.0033480511631304756\nBatch 19635/490910 - 0.010s/step - loss: 0.2625751005336536 - lr: 0.0033197993030330995\nBatch 29453/490910 - 0.010s/step - loss: 0.3314246312823442 - lr: 0.003291441678170216\nBatch 39271/490910 - 0.010s/step - loss: 0.5007398826724465 - lr: 0.003262982766357092\nBatch 49089/490910 - 0.010s/step - loss: 0.19751543036600763 - lr: 0.003234427061402724\nBatch 58907/490910 - 0.010s/step - loss: 0.2565613067544804 - lr: 0.003205779072400246\nBatch 68725/490910 - 0.010s/step - loss: 0.3234038837779564 - lr: 0.0031770433230149187\nBatch 78543/490910 - 0.010s/step - loss: 0.19898513269819962 - lr: 0.003148224350769821\nBatch 88361/490910 - 0.010s/step - loss: 0.3643534012251915 - lr: 0.003119326706329351\nBatch 98179/490910 - 0.010s/step - loss: 0.2558834800805178 - lr: 0.00309035495278065\nBatch 107997/490910 - 0.010s/step - loss: 0.2725352314990458 - lr: 0.0030613136649130725\nBatch 117815/490910 - 0.010s/step - loss: 0.2845272687109167 - lr: 0.003032207428495799\nBatch 127633/490910 - 0.010s/step - loss: 0.191816582047375 - lr: 0.003003040839553722\nBatch 137451/490910 - 0.010s/step - loss: 0.20193656491327033 - lr: 0.002973818503641708\nBatch 147269/490910 - 0.010s/step - loss: 0.27972611394117214 - lr: 0.0029445450351173576\nBatch 157087/490910 - 0.010s/step - loss: 0.2974266793199808 - lr: 0.0029152250564123783\nBatch 166905/490910 - 0.010s/step - loss: 0.36564775061353294 - lr: 0.0028858631973026697\nBatch 176723/490910 - 0.010s/step - loss: 0.4087538207974304 - lr: 0.002856464094177266\nBatch 186541/490910 - 0.010s/step - loss: 0.39303857436125506 - lr: 0.0028270323893062246\nBatch 196359/490910 - 0.010s/step - loss: 0.3125100376366746 - lr: 0.002797572730107584\nBatch 206177/490910 - 0.010s/step - loss: 0.3686526224952829 - lr: 0.002768089768413518\nBatch 215995/490910 - 0.010s/step - loss: 0.33950664634201855 - lr: 0.0027385881597357838\nBatch 225813/490910 - 0.010s/step - loss: 0.30465052331924697 - lr: 0.0027090725625305923\nBatch 235631/490910 - 0.010s/step - loss: 0.24225016331082344 - lr: 0.002679547637463016\nBatch 245449/490910 - 0.010s/step - loss: 0.3366887118503448 - lr: 0.0026500180466710456\nBatch 255267/490910 - 0.010s/step - loss: 0.37179231669440377 - lr: 0.002620488453029413\nBatch 265085/490910 - 0.010s/step - loss: 0.29834802215700723 - lr: 0.002590963519413299\nBatch 274903/490910 - 0.010s/step - loss: 0.280260675478052 - lr: 0.0025614479079620455\nBatch 284721/490910 - 0.010s/step - loss: 0.27661649429330964 - lr: 0.0025319462793429726\nBatch 294539/490910 - 0.010s/step - loss: 0.252114055128068 - lr: 0.0025024632920154426\nBatch 304357/490910 - 0.010s/step - loss: 0.18183671747557978 - lr: 0.002473003601495258\nBatch 314175/490910 - 0.010s/step - loss: 0.2950535519168094 - lr: 0.0024435718596195395\nBatch 333811/490910 - 0.010s/step - loss: 0.2972724921387626 - lr: 0.0023848108063499428\nBatch 343629/490910 - 0.010s/step - loss: 0.2881532442754764 - lr: 0.0023554907736295307\nBatch 353447/490910 - 0.010s/step - loss: 0.2416933633536112 - lr: 0.0023262172454353632\nBatch 363265/490910 - 0.010s/step - loss: 0.37624692721186137 - lr: 0.0022969948442085665\nBatch 373083/490910 - 0.010s/step - loss: 0.34522338159307214 - lr: 0.002267828184317057\nBatch 382901/490910 - 0.010s/step - loss: 0.16221984905162498 - lr: 0.0022387218713269042\nBatch 392719/490910 - 0.010s/step - loss: 0.18846797302894994 - lr: 0.002209680501275091\nBatch 402537/490910 - 0.010s/step - loss: 0.22535588192120026 - lr: 0.0021807086599437775\nBatch 412355/490910 - 0.010s/step - loss: 0.25815864128870164 - lr: 0.0021518109221361774\nBatch 422173/490910 - 0.010s/step - loss: 0.2678347736438457 - lr: 0.002122991850954175\nBatch 431991/490910 - 0.010s/step - loss: 0.23778547164292527 - lr: 0.0020942559970777933\nBatch 441809/490910 - 0.010s/step - loss: 0.25301916673411434 - lr: 0.0020656078980466086\nBatch 451627/490910 - 0.010s/step - loss: 0.24593752196081775 - lr: 0.0020370520775432567\nBatch 461445/490910 - 0.010s/step - loss: 0.30340623306321085 - lr: 0.0020085930446791162\nBatch 471263/490910 - 0.010s/step - loss: 0.24051200682143678 - lr: 0.0019802352932823007\nBatch 481081/490910 - 0.010s/step - loss: 0.23618862546625988 - lr: 0.0019519833011880552\nBatch 490899/490910 - 0.010s/step - loss: 0.21830384155504298 - lr: 0.0019238415295316856\ntrain loss: 0.28440505128229\nEpoch 4/5\nBatch 9817/490910 - 0.010s/step - loss: 0.27125457392363866 - lr: 0.0018957859353482592\nBatch 19635/490910 - 0.010s/step - loss: 0.2624529455440302 - lr: 0.00186787804120157\nBatch 29453/490910 - 0.010s/step - loss: 0.3310709713790683 - lr: 0.0018400936481472172\nBatch 39271/490910 - 0.010s/step - loss: 0.5004026161375488 - lr: 0.001812437143484206\nBatch 49089/490910 - 0.010s/step - loss: 0.19735612682203266 - lr: 0.0017849128943173038\nBatch 58907/490910 - 0.010s/step - loss: 0.25640229384433255 - lr: 0.0017575252468674547\nBatch 68725/490910 - 0.010s/step - loss: 0.3230751199041827 - lr: 0.0017302785257854877\nBatch 78543/490910 - 0.010s/step - loss: 0.1988203393650748 - lr: 0.0017031770334692295\nBatch 88361/490910 - 0.010s/step - loss: 0.36387428291518387 - lr: 0.0016762250493841345\nBatch 98179/490910 - 0.010s/step - loss: 0.25568600111510276 - lr: 0.0016494268293875392\nBatch 107997/490910 - 0.010s/step - loss: 0.2722770278379063 - lr: 0.0016227866050566367\nBatch 117815/490910 - 0.010s/step - loss: 0.2843728934354544 - lr: 0.0015963085830202858\nBatch 127633/490910 - 0.010s/step - loss: 0.19166597639195154 - lr: 0.0015699969442947695\nBatch 137451/490910 - 0.010s/step - loss: 0.20184248245882208 - lr: 0.001543855843623587\nBatch 147269/490910 - 0.010s/step - loss: 0.27964070272577113 - lr: 0.0015178894088213996\nBatch 157087/490910 - 0.010s/step - loss: 0.2972684543182169 - lr: 0.0014921017401222233\nBatch 166905/490910 - 0.010s/step - loss: 0.36538515949724626 - lr: 0.00146649690953199\nBatch 176723/490910 - 0.010s/step - loss: 0.40848813563347 - lr: 0.0014410789601855454\nBatch 186541/490910 - 0.010s/step - loss: 0.3930528646830737 - lr: 0.0014158519057082253\nBatch 196359/490910 - 0.010s/step - loss: 0.31243293556166757 - lr: 0.0013908197295820807\nBatch 206177/490910 - 0.010s/step - loss: 0.3685530424370366 - lr: 0.0013659863845168663\nBatch 215995/490910 - 0.010s/step - loss: 0.3393293622620123 - lr: 0.001341355791825883\nBatch 225813/490910 - 0.010s/step - loss: 0.3045891561061842 - lr: 0.0013169318408067902\nBatch 235631/490910 - 0.010s/step - loss: 0.24219717093116178 - lr: 0.0012927183881274586\nBatch 245449/490910 - 0.010s/step - loss: 0.3365328247893399 - lr: 0.0012687192572169868\nBatch 255267/490910 - 0.010s/step - loss: 0.371599647699709 - lr: 0.0012449382376619566\nBatch 265085/490910 - 0.010s/step - loss: 0.29823496293130086 - lr: 0.001221379084608048\nBatch 274903/490910 - 0.010s/step - loss: 0.28013265858440195 - lr: 0.0011980455181670694\nBatch 284721/490910 - 0.010s/step - loss: 0.276194237565698 - lr: 0.0011749412228295435\nBatch 294539/490910 - 0.010s/step - loss: 0.2519178276763571 - lr: 0.001152069846882899\nBatch 304357/490910 - 0.010s/step - loss: 0.1816920508365159 - lr: 0.0011294350018353969\nBatch 314175/490910 - 0.010s/step - loss: 0.2948978959219817 - lr: 0.0011070402618458426\nBatch 323993/490910 - 0.010s/step - loss: 0.3159206618462308 - lr: 0.0010848891631592182\nBatch 333811/490910 - 0.010s/step - loss: 0.29718194998983644 - lr: 0.0010629852035482859\nBatch 343629/490910 - 0.010s/step - loss: 0.2880965121233696 - lr: 0.0010413318417612728\nBatch 353447/490910 - 0.010s/step - loss: 0.24165558870857606 - lr: 0.001019932496975717\nBatch 363265/490910 - 0.010s/step - loss: 0.37621375891069064 - lr: 0.0009987905482585608\nBatch 373083/490910 - 0.010s/step - loss: 0.34500388702767354 - lr: 0.000977909334032581\nBatch 382901/490910 - 0.010s/step - loss: 0.16213038681457448 - lr: 0.0009572921515492311\nBatch 392719/490910 - 0.010s/step - loss: 0.18834800087389786 - lr: 0.0009369422563679916\nBatch 402537/490910 - 0.010s/step - loss: 0.22520387462549174 - lr: 0.0009168628618422981\nBatch 412355/490910 - 0.010s/step - loss: 0.25797247238507287 - lr: 0.0008970571386121393\nBatch 422173/490910 - 0.010s/step - loss: 0.26766807461101666 - lr: 0.00087752821410339\nBatch 431991/490910 - 0.010s/step - loss: 0.23751396440306477 - lr: 0.0008582791720339849\nBatch 441809/490910 - 0.010s/step - loss: 0.25290479474710664 - lr: 0.0008393130519269724\nBatch 451627/490910 - 0.010s/step - loss: 0.24572111720328912 - lr: 0.0008206328486305662\nBatch 461445/490910 - 0.010s/step - loss: 0.30319196777674373 - lr: 0.0008022415118452383\nBatch 471263/490910 - 0.010s/step - loss: 0.24035469048676822 - lr: 0.0007841419456579525\nBatch 481081/490910 - 0.010s/step - loss: 0.23609932891024327 - lr: 0.0007663370080835843\nBatch 490899/490910 - 0.010s/step - loss: 0.2182215126462768 - lr: 0.0007488295106136358\ntrain loss: 0.2842419057065079\nEpoch 5/5\nBatch 9817/490910 - 0.010s/step - loss: 0.2711885305683863 - lr: 0.0007316048454697974\nBatch 19635/490910 - 0.010s/step - loss: 0.26220339614450994 - lr: 0.0007147007842833971\nBatch 29453/490910 - 0.010s/step - loss: 0.3307495321801479 - lr: 0.0006981023168275502\nBatch 39271/490910 - 0.010s/step - loss: 0.5001387819209542 - lr: 0.0006818120640859016\nBatch 49089/490910 - 0.010s/step - loss: 0.1972174488752094 - lr: 0.0006658325983734012\nBatch 58907/490910 - 0.010s/step - loss: 0.25622218977288097 - lr: 0.0006501664429301249\nBatch 68725/490910 - 0.010s/step - loss: 0.3228348742914002 - lr: 0.0006348160715228402\nBatch 78543/490910 - 0.010s/step - loss: 0.198598173217585 - lr: 0.0006197839080543869\nBatch 88361/490910 - 0.010s/step - loss: 0.3635461486850968 - lr: 0.000605072326180929\nBatch 98179/490910 - 0.010s/step - loss: 0.2554613566060241 - lr: 0.0005906836489371418\nBatch 107997/490910 - 0.010s/step - loss: 0.27193871748865706 - lr: 0.0005766201483693961\nBatch 117815/490910 - 0.010s/step - loss: 0.2842182451147676 - lr: 0.0005628840451769855\nBatch 127633/490910 - 0.010s/step - loss: 0.19153834465264297 - lr: 0.0005494775083614697\nBatch 137451/490910 - 0.010s/step - loss: 0.20172270002379714 - lr: 0.000536402654884178\nBatch 147269/490910 - 0.010s/step - loss: 0.27956866301037636 - lr: 0.0005236615493319294\nBatch 157087/490910 - 0.010s/step - loss: 0.2972354017248171 - lr: 0.0005112562035910215\nBatch 166905/490910 - 0.010s/step - loss: 0.36527977118685606 - lr: 0.000499188576529549\nBatch 176723/490910 - 0.010s/step - loss: 0.4083428664480515 - lr: 0.0004874605736880818\nBatch 186541/490910 - 0.010s/step - loss: 0.39293642269533197 - lr: 0.00047607404697877465\nBatch 196359/490910 - 0.010s/step - loss: 0.3123903573141789 - lr: 0.00046503079439293924\nBatch 206177/490910 - 0.010s/step - loss: 0.36846856803899447 - lr: 0.00045433255971713234\nBatch 215995/490910 - 0.010s/step - loss: 0.33926414176952613 - lr: 0.0004439810322578021\nBatch 225813/490910 - 0.010s/step - loss: 0.3045678344528828 - lr: 0.00043397784657453866\nBatch 235631/490910 - 0.010s/step - loss: 0.24216962025800967 - lr: 0.0004243245822219691\nBatch 245449/490910 - 0.010s/step - loss: 0.3364902931834875 - lr: 0.000415022763500337\nBatch 255267/490910 - 0.010s/step - loss: 0.3715252162492896 - lr: 0.0004060738592148065\nBatch 265085/490910 - 0.010s/step - loss: 0.29818776200369324 - lr: 0.00039747928244353417\nBatch 274903/490910 - 0.010s/step - loss: 0.2800075946903901 - lr: 0.00038924039031453087\nBatch 284721/490910 - 0.010s/step - loss: 0.2761117895324459 - lr: 0.0003813584837913701\nBatch 294539/490910 - 0.010s/step - loss: 0.25180455463348206 - lr: 0.0003738348074677543\nBatch 304357/490910 - 0.010s/step - loss: 0.1816269721787284 - lr: 0.00036667054937099166\nBatch 314175/490910 - 0.010s/step - loss: 0.29485071055954604 - lr: 0.0003598668407743953\nBatch 323993/490910 - 0.010s/step - loss: 0.31585705892009674 - lr: 0.0003534247560186547\nBatch 333811/490910 - 0.010s/step - loss: 0.29714049248955954 - lr: 0.00034734531234218764\nBatch 343629/490910 - 0.010s/step - loss: 0.28807720604290427 - lr: 0.00034162946972051496\nBatch 353447/490910 - 0.010s/step - loss: 0.24164410933738745 - lr: 0.0003362781307146754\nBatch 363265/490910 - 0.010s/step - loss: 0.3760670704286554 - lr: 0.00033129214032870635\nBatch 373083/490910 - 0.010s/step - loss: 0.3449350278731606 - lr: 0.00032667228587621237\nBatch 382901/490910 - 0.010s/step - loss: 0.16248128912463802 - lr: 0.00032241929685604604\nBatch 392719/490910 - 0.010s/step - loss: 0.1883314277703179 - lr: 0.0003185338448371153\nBatch 402537/490910 - 0.010s/step - loss: 0.22519057058708553 - lr: 0.00031501654335233903\nBatch 412355/490910 - 0.010s/step - loss: 0.2578992071214522 - lr: 0.0003118679478017683\nBatch 422173/490910 - 0.010s/step - loss: 0.26759573532677056 - lr: 0.00030908855536488386\nBatch 431991/490910 - 0.010s/step - loss: 0.23747549064868723 - lr: 0.00030667880492209106\nBatch 441809/490910 - 0.010s/step - loss: 0.25285176652447405 - lr: 0.00030463907698541684\nBatch 451627/490910 - 0.010s/step - loss: 0.24570763670932522 - lr: 0.0003029696936384254\nBatch 461445/490910 - 0.010s/step - loss: 0.3031443687382365 - lr: 0.00030167091848535996\nBatch 471263/490910 - 0.010s/step - loss: 0.24031206943894579 - lr: 0.00030074295660951757\nBatch 481081/490910 - 0.010s/step - loss: 0.2360499348727818 - lr: 0.0003001859545408659\nBatch 490899/490910 - 0.010s/step - loss: 0.21818520742462655 - lr: 0.0003000000002329052\ntrain loss: 0.284147052977025\nEpochs: 5\nTrain error: 0.2844331\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"torch.save({\n \"model_state_dict\": model.state_dict()\n },\n \"/kaggle/working/model.pth\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T14:55:57.387484Z","iopub.execute_input":"2025-01-03T14:55:57.387828Z","iopub.status.idle":"2025-01-03T14:55:57.400968Z","shell.execute_reply.started":"2025-01-03T14:55:57.387794Z","shell.execute_reply":"2025-01-03T14:55:57.400350Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}